{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a3874e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool\")\n",
    "import denoise\n",
    "from model import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00b1fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/csi_dataset/rssi/rssi_for_4AP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a930ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = {\n",
    "        1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "        36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "        2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "        6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "        12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "        16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "        20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "        22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "        26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "        41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "        44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "        47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f35bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class RSSIDataset(Dataset):\n",
    "    def __init__(self, rssi_data, labels, coordinates_dict, augment=False, rssi_mask_prob=0.01):\n",
    "        self.rssi_data = torch.tensor(rssi_data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)  # one-hot labels\n",
    "        self.augment = augment\n",
    "        self.rssi_mask_prob = rssi_mask_prob\n",
    "        self.coordinates_dict = coordinates_dict\n",
    "\n",
    "        # 將 class index（從 one-hot）反解為 ID（1~49）\n",
    "        self.label_ids = torch.argmax(self.labels, dim=1).numpy() + 1\n",
    "\n",
    "        # 對應到回歸座標\n",
    "        self.reg_coords = torch.tensor(\n",
    "            [coordinates_dict[int(lid)] for lid in self.label_ids],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rssi_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rssi = self.rssi_data[idx]\n",
    "        label = self.labels[idx]              # one-hot\n",
    "        reg_target = self.reg_coords[idx]     # 對應的 (x, y)\n",
    "\n",
    "        if self.augment:\n",
    "            mask = torch.rand(rssi.shape) < self.rssi_mask_prob\n",
    "            rssi = rssi.clone()  # 避免修改原始資料\n",
    "            rssi[mask] = 0.0\n",
    "\n",
    "        return rssi, label, reg_target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d2b03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假設你已經有 df_merged_all\n",
    "rssi_columns = ['AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi']\n",
    "\n",
    "# 1. 填補 RSSI 缺值\n",
    "data[rssi_columns] = data[rssi_columns].fillna(0)\n",
    "\n",
    "# 2. Label 編碼（如果是整數，可以直接用）\n",
    "labels = data['Label'].values\n",
    "rssi_data = data[rssi_columns].values\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30cce09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-60., -68., -61., -59.],\n",
       "       [-62., -70., -59., -59.],\n",
       "       [-61., -69., -62., -55.],\n",
       "       ...,\n",
       "       [-65., -65., -61., -60.],\n",
       "       [-65., -65., -61., -58.],\n",
       "       [-66., -64., -60., -59.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rssi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3c82d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 11, 11, ..., 35, 35, 35])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7dfec9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "one_hot_labels = encoder.fit_transform(np.array(labels).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a755783",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "    rssi_data, one_hot_labels, test_size=0.3, random_state=42)\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    temp_data, temp_labels, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18bd73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RSSIDataset(train_data, train_labels,coordinates, augment=True)\n",
    "val_dataset = RSSIDataset(val_data, val_labels, coordinates)\n",
    "test_dataset = RSSIDataset(test_data, test_labels, coordinates)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d382cda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_input, train_label \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(train_input\u001b[38;5;241m.\u001b[39mshape, train_label\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# for train_input, train_label in train_loader:\n",
    "#     print(train_input.shape, train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d6972ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(train_label[1])\n",
    "argmax_label = torch.argmax(train_label[1])\n",
    "print(argmax_label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de6149e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d65a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSSIClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(RSSIClassifier, self).__init__()\n",
    "        self.fc1 =torch.nn.Linear(input_size, 128)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
    "        self.dropout1 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f442064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RSSIClassifier(4, num_classes=49).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d2c725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 49])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RSSIClassifier                           [1, 49]                   --\n",
       "├─Linear: 1-1                            [1, 128]                  640\n",
       "├─BatchNorm1d: 1-2                       [1, 128]                  256\n",
       "├─Dropout: 1-3                           [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 64]                   8,256\n",
       "├─BatchNorm1d: 1-5                       [1, 64]                   128\n",
       "├─Dropout: 1-6                           [1, 64]                   --\n",
       "├─Linear: 1-7                            [1, 49]                   3,185\n",
       "==========================================================================================\n",
       "Total params: 12,465\n",
       "Trainable params: 12,465\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.01\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.05\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dummy_rssi = torch.randn(32, 4).to(device)       # RSSI 輸入: (batch=1, 4-d)\n",
    "output = model(dummy_rssi)\n",
    "print(\"Output shape:\", output.shape)  # 預期: (1, 49)\n",
    "\n",
    "# 安裝 torchinfo (如果還沒安裝)\n",
    "# pip install torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "dummy_rssi = torch.randn(1, 4).to(device)\n",
    "summary(model, input_data=dummy_rssi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1418ac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcs/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失函數\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 優化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 學習率調整器\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b14bf051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-61., -66., -56., -52.]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset[0][0], train_loader.dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7f993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ff9490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] | Train Loss: 3.2215 | Train Acc: 15.11% | Val Loss: 2.2638 | Val Acc: 51.18%\n",
      "✅ 儲存最佳模型 (Val Loss: 2.2638) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [2/200] | Train Loss: 2.4488 | Train Acc: 27.38% | Val Loss: 1.6515 | Val Acc: 63.86%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.6515) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [3/200] | Train Loss: 2.2237 | Train Acc: 32.02% | Val Loss: 1.4194 | Val Acc: 68.53%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.4194) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [4/200] | Train Loss: 2.1383 | Train Acc: 34.36% | Val Loss: 1.2947 | Val Acc: 70.59%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.2947) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [5/200] | Train Loss: 2.0915 | Train Acc: 35.13% | Val Loss: 1.2453 | Val Acc: 73.35%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.2453) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [6/200] | Train Loss: 2.0690 | Train Acc: 35.78% | Val Loss: 1.1628 | Val Acc: 72.16%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.1628) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [7/200] | Train Loss: 2.0701 | Train Acc: 35.62% | Val Loss: 1.1280 | Val Acc: 70.35%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.1280) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [8/200] | Train Loss: 2.0776 | Train Acc: 35.25% | Val Loss: 1.1283 | Val Acc: 71.65%\n",
      "Epoch [9/200] | Train Loss: 2.0872 | Train Acc: 35.11% | Val Loss: 1.0957 | Val Acc: 72.22%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.0957) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [10/200] | Train Loss: 2.0932 | Train Acc: 34.83% | Val Loss: 1.1175 | Val Acc: 71.14%\n",
      "Epoch [11/200] | Train Loss: 2.1237 | Train Acc: 33.83% | Val Loss: 1.0698 | Val Acc: 72.55%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.0698) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [12/200] | Train Loss: 2.1353 | Train Acc: 33.90% | Val Loss: 1.1776 | Val Acc: 70.14%\n",
      "Epoch [13/200] | Train Loss: 2.1458 | Train Acc: 33.10% | Val Loss: 1.0627 | Val Acc: 72.10%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.0627) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [14/200] | Train Loss: 2.1732 | Train Acc: 32.76% | Val Loss: 1.0400 | Val Acc: 73.65%\n",
      "✅ 儲存最佳模型 (Val Loss: 1.0400) 至 /media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\n",
      "Epoch [15/200] | Train Loss: 2.2037 | Train Acc: 32.50% | Val Loss: 1.1459 | Val Acc: 67.16%\n",
      "Epoch [16/200] | Train Loss: 2.2196 | Train Acc: 31.90% | Val Loss: 1.1846 | Val Acc: 69.27%\n",
      "Epoch [17/200] | Train Loss: 2.2286 | Train Acc: 31.52% | Val Loss: 1.0812 | Val Acc: 74.39%\n",
      "Epoch [18/200] | Train Loss: 2.2729 | Train Acc: 29.87% | Val Loss: 1.0980 | Val Acc: 71.43%\n",
      "Epoch [19/200] | Train Loss: 2.2652 | Train Acc: 30.45% | Val Loss: 1.0475 | Val Acc: 74.06%\n",
      "Epoch [20/200] | Train Loss: 2.3084 | Train Acc: 29.13% | Val Loss: 1.0585 | Val Acc: 72.92%\n",
      "Epoch [21/200] | Train Loss: 2.3113 | Train Acc: 29.34% | Val Loss: 1.0522 | Val Acc: 73.37%\n",
      "Epoch [22/200] | Train Loss: 2.3397 | Train Acc: 29.22% | Val Loss: 1.1050 | Val Acc: 67.90%\n",
      "Epoch [23/200] | Train Loss: 2.3678 | Train Acc: 27.60% | Val Loss: 1.1689 | Val Acc: 68.94%\n",
      "Epoch [24/200] | Train Loss: 2.3712 | Train Acc: 28.05% | Val Loss: 1.1767 | Val Acc: 69.94%\n",
      "Epoch [25/200] | Train Loss: 2.3956 | Train Acc: 27.59% | Val Loss: 1.2280 | Val Acc: 63.35%\n",
      "Epoch [26/200] | Train Loss: 2.4043 | Train Acc: 27.21% | Val Loss: 1.1591 | Val Acc: 69.43%\n",
      "Epoch [27/200] | Train Loss: 2.4357 | Train Acc: 26.49% | Val Loss: 1.1785 | Val Acc: 68.61%\n",
      "Epoch [28/200] | Train Loss: 2.4370 | Train Acc: 25.72% | Val Loss: 1.1745 | Val Acc: 68.49%\n",
      "Epoch [29/200] | Train Loss: 2.4811 | Train Acc: 25.50% | Val Loss: 1.1480 | Val Acc: 71.12%\n",
      "Epoch [30/200] | Train Loss: 2.4916 | Train Acc: 25.20% | Val Loss: 1.1980 | Val Acc: 70.00%\n",
      "Epoch [31/200] | Train Loss: 2.5162 | Train Acc: 24.26% | Val Loss: 1.3048 | Val Acc: 68.27%\n",
      "Epoch [32/200] | Train Loss: 2.5252 | Train Acc: 24.82% | Val Loss: 1.2305 | Val Acc: 65.80%\n",
      "Epoch [33/200] | Train Loss: 2.5391 | Train Acc: 24.10% | Val Loss: 1.2726 | Val Acc: 67.94%\n",
      "Epoch [34/200] | Train Loss: 2.5504 | Train Acc: 24.33% | Val Loss: 1.2725 | Val Acc: 68.22%\n",
      "⏹️ Early stop at epoch 34\n",
      "✅ 訓練完成！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 儲存最佳模型相關設定\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = \"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\"\n",
    "\n",
    "# 訓練參數\n",
    "epochs = 200\n",
    "\n",
    "# Early Stopping 參數\n",
    "patience = 20\n",
    "counter = 0  \n",
    "\n",
    "# 紀錄訓練過程中的 loss 和 accuracy\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- 訓練階段 ----\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for rssi_inputs, labels in train_loader:\n",
    "        rssi_inputs = rssi_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rssi_inputs)\n",
    "\n",
    "        loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * rssi_inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        train_correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = 100 * train_correct / total_train\n",
    "\n",
    "    # ---- 驗證階段 ----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for rssi_inputs, labels in val_loader:\n",
    "            rssi_inputs = rssi_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(rssi_inputs)\n",
    "            loss = criterion(outputs, torch.argmax(labels,dim=1))\n",
    "\n",
    "            val_loss += loss.item() * rssi_inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            val_correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = 100 * val_correct / total_val\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # 儲存最佳模型\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ 儲存最佳模型 (Val Loss: {best_val_loss:.4f}) 至 {best_model_path}\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(f\"⏹️ Early stop at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"✅ 訓練完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "385b4ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rssi_input, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     14\u001b[0m         rssi_inputs, labels \u001b[38;5;241m=\u001b[39m rssi_input\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(rssi_inputs)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# 載入最佳模型\n",
    "model.load_state_dict(torch.load(\"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# 測試模型\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for rssi_input, labels in test_loader:\n",
    "        rssi_inputs, labels = rssi_input.to(device), labels.to(device)\n",
    "        outputs = model(rssi_inputs)\n",
    "        loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
    "            \n",
    "        test_loss += loss.item() * rssi_inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "        # 儲存真實標籤與預測標籤\n",
    "        all_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"📊 測試損失: {test_loss:.4f}, 測試準確率: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45040a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance error: 0.6830781652838999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "adjusted_labels = np.array(all_labels) + 1\n",
    "adjusted_predictions = np.array(all_predictions) + 1\n",
    "def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "    coordinates: dict, label -> (x, y)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        # 取出對應的座標\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "            print(f\"Warning: Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        # 計算歐氏距離\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors) if errors else None\n",
    "\n",
    "COORDINATES = {\n",
    "    # 下邊界 (1-10 和 40-31)\n",
    "    1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "    36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "\n",
    "    # 左邊界 (1-11)\n",
    "    2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "    6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "\n",
    "    # 上邊界 (11-21)\n",
    "    12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "    16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "    20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "\n",
    "    # 右邊界 (21-31)\n",
    "    22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "    26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "\n",
    "    # 中間點 (41-49)\n",
    "    41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "    44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "    47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "}\n",
    "\n",
    "mean_error = compute_mean_distance_error(adjusted_labels, adjusted_predictions, COORDINATES)\n",
    "print(\"Mean distance error:\", mean_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00606b2d",
   "metadata": {},
   "source": [
    "# 雙輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2c2c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RSSIClsRegNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(RSSIClsRegNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # 分支 1：分類\n",
    "        self.classifier = nn.Linear(64, num_classes)\n",
    "\n",
    "        # 分支 2：回歸 (預測 X, Y)\n",
    "        self.regressor = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        cls_out = self.classifier(x)  # 分類輸出\n",
    "        reg_out = self.regressor(x)   # 回歸輸出 (x, y 座標)\n",
    "\n",
    "        return cls_out, reg_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d56eb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcs/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m target_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m class_out, reg_out \u001b[38;5;241m=\u001b[39m model(rssi_inputs)\n\u001b[1;32m     47\u001b[0m loss_cls \u001b[38;5;241m=\u001b[39m criterion_cls(class_out, target_class)\n\u001b[1;32m     48\u001b[0m true_coords \u001b[38;5;241m=\u001b[39m labels_to_coords(target_class, COORDINATES)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha = 0.1  # 回歸損失權重\n",
    "epochs = 200\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = \"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_save_rssi_dnn/rssi_cls_reg.pth\"\n",
    "patience = 20\n",
    "counter = 0\n",
    "save_enabled = True\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15, verbose=True)\n",
    "\n",
    "# 儲存訓練記錄\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Loss 定義\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_reg = nn.MSELoss()\n",
    "\n",
    "# Label ID → 座標對應函數\n",
    "def labels_to_coords(label_tensor, coord_dict):\n",
    "    coords = [coord_dict[int(l.item()) + 1] for l in label_tensor.cpu()]\n",
    "    return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)\n",
    "\n",
    "# 訓練迴圈\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_class_loss = 0.0\n",
    "    train_reg_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for rssi_inputs, labels, _ in train_loader:\n",
    "        rssi_inputs = rssi_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        target_class = torch.argmax(labels, dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        class_out, reg_out = model(rssi_inputs)\n",
    "\n",
    "        loss_cls = criterion_cls(class_out, target_class)\n",
    "        true_coords = labels_to_coords(target_class, COORDINATES)\n",
    "        loss_reg = criterion_reg(reg_out, true_coords)\n",
    "        loss = loss_cls + alpha * loss_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = rssi_inputs.size(0)\n",
    "        train_loss += loss.item() * batch_size\n",
    "        train_class_loss += loss_cls.item() * batch_size\n",
    "        train_reg_loss += loss_reg.item() * batch_size\n",
    "\n",
    "        _, predicted = torch.max(class_out, 1)\n",
    "        train_correct += (predicted == target_class).sum().item()\n",
    "        total_train += batch_size\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_train_class_loss = train_class_loss / len(train_loader.dataset)\n",
    "    avg_train_reg_loss = train_reg_loss / len(train_loader.dataset)\n",
    "    train_acc = 100 * train_correct / total_train\n",
    "\n",
    "    # ----- 驗證 -----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_class_loss = 0.0\n",
    "    val_reg_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for rssi_inputs, labels in val_loader:\n",
    "            rssi_inputs = rssi_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            target_class = torch.argmax(labels, dim=1)\n",
    "\n",
    "            class_out, reg_out = model(rssi_inputs)\n",
    "            loss_cls = criterion_cls(class_out, target_class)\n",
    "            true_coords = labels_to_coords(target_class, COORDINATES)\n",
    "            loss_reg = criterion_reg(reg_out, true_coords)\n",
    "            loss = loss_cls + alpha * loss_reg\n",
    "\n",
    "            batch_size = rssi_inputs.size(0)\n",
    "            val_loss += loss.item() * batch_size\n",
    "            val_class_loss += loss_cls.item() * batch_size\n",
    "            val_reg_loss += loss_reg.item() * batch_size\n",
    "\n",
    "            _, predicted = torch.max(class_out, 1)\n",
    "            val_correct += (predicted == target_class).sum().item()\n",
    "            total_val += batch_size\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    avg_val_class_loss = val_class_loss / len(val_loader.dataset)\n",
    "    avg_val_reg_loss = val_reg_loss / len(val_loader.dataset)\n",
    "    val_acc = 100 * val_correct / total_val\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} (Cls: {avg_train_class_loss:.4f}, Reg: {avg_train_reg_loss:.4f}) | \"\n",
    "          f\"Train Acc: {train_acc:.2f}% || \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} (Cls: {avg_val_class_loss:.4f}, Reg: {avg_val_reg_loss:.4f}) | \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # 儲存模型\n",
    "    if save_enabled:\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"✅ 儲存最佳模型 (Val Loss: {best_val_loss:.4f}) 至 {best_model_path}\")\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"⏳ 沒改善: {counter}/{patience}\")\n",
    "            if counter >= patience:\n",
    "                print(f\"⚠️ 已達 patience={patience}，提前停止訓練\")\n",
    "                break\n",
    "\n",
    "print(\"🎉 訓練完成！\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
