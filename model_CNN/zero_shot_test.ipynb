{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b98af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('./')\n",
    "from csidataset import *\n",
    "import data_loader\n",
    "from data_loader import *\n",
    "sys.path.append(\"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool\")\n",
    "import denoise\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3339992",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_path = \"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/csi_dataset/localization_phone/1223_phone/5G/20MHz/csv/all\"\n",
    "rssi_path = \"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/csi_dataset/rssi/rssi_for_4AP.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1eb6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data CSI\n",
    "reference_points = {}\n",
    "spacing = 0.6  # 每隔 0.6m\n",
    "\n",
    "for ref_id, coord in data_loader.COORDINATES.items():\n",
    "    folder_path = os.path.join(csi_path, f\"reference_point_{ref_id}.xlsx\")\n",
    "    reference_points[folder_path] = (ref_id, coord)\n",
    "\n",
    "data, rp_labels, coord_labels = load_data(reference_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709281f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi = data\n",
    "csi[\"Label\"] = rp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08459af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(rssi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ee7e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24500, 103)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>AP1_Rssi</th>\n",
       "      <th>AP2_Rssi</th>\n",
       "      <th>AP3_Rssi</th>\n",
       "      <th>AP4_Rssi</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>919.592301</td>\n",
       "      <td>929.595611</td>\n",
       "      <td>877.760787</td>\n",
       "      <td>898.203763</td>\n",
       "      <td>851.400023</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.387518</td>\n",
       "      <td>-1.581549</td>\n",
       "      <td>-1.708760</td>\n",
       "      <td>-2.080869</td>\n",
       "      <td>-2.287379</td>\n",
       "      <td>-2.467120</td>\n",
       "      <td>-2.666997</td>\n",
       "      <td>-2.982241</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>698.204841</td>\n",
       "      <td>732.963846</td>\n",
       "      <td>684.079674</td>\n",
       "      <td>694.257877</td>\n",
       "      <td>651.079872</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.677159</td>\n",
       "      <td>-2.877730</td>\n",
       "      <td>-3.051501</td>\n",
       "      <td>2.738820</td>\n",
       "      <td>2.503722</td>\n",
       "      <td>2.256683</td>\n",
       "      <td>2.035376</td>\n",
       "      <td>1.737005</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>745.268408</td>\n",
       "      <td>768.188128</td>\n",
       "      <td>706.606680</td>\n",
       "      <td>713.252410</td>\n",
       "      <td>681.482208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176051</td>\n",
       "      <td>-0.063704</td>\n",
       "      <td>-0.251636</td>\n",
       "      <td>-0.776139</td>\n",
       "      <td>-1.023850</td>\n",
       "      <td>-1.275624</td>\n",
       "      <td>-1.535994</td>\n",
       "      <td>-1.899522</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>830.278267</td>\n",
       "      <td>829.860832</td>\n",
       "      <td>804.005597</td>\n",
       "      <td>796.492310</td>\n",
       "      <td>786.787138</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.031820</td>\n",
       "      <td>-1.194379</td>\n",
       "      <td>-1.338067</td>\n",
       "      <td>-1.666445</td>\n",
       "      <td>-1.878363</td>\n",
       "      <td>-2.100073</td>\n",
       "      <td>-2.369892</td>\n",
       "      <td>-2.666982</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>906.099884</td>\n",
       "      <td>903.507056</td>\n",
       "      <td>910.843565</td>\n",
       "      <td>896.688352</td>\n",
       "      <td>892.235955</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.445534</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.783166</td>\n",
       "      <td>-1.090942</td>\n",
       "      <td>-1.286103</td>\n",
       "      <td>-1.497279</td>\n",
       "      <td>-1.784787</td>\n",
       "      <td>-2.076610</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24495</th>\n",
       "      <td>49</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>397.615392</td>\n",
       "      <td>416.889674</td>\n",
       "      <td>395.588170</td>\n",
       "      <td>413.019370</td>\n",
       "      <td>382.733589</td>\n",
       "      <td>...</td>\n",
       "      <td>2.183710</td>\n",
       "      <td>2.005190</td>\n",
       "      <td>1.826107</td>\n",
       "      <td>1.364322</td>\n",
       "      <td>1.150287</td>\n",
       "      <td>0.872978</td>\n",
       "      <td>0.573063</td>\n",
       "      <td>0.255977</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24496</th>\n",
       "      <td>49</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>643.708785</td>\n",
       "      <td>646.260010</td>\n",
       "      <td>627.624888</td>\n",
       "      <td>621.498994</td>\n",
       "      <td>605.152873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494557</td>\n",
       "      <td>-0.782703</td>\n",
       "      <td>-1.053078</td>\n",
       "      <td>-1.631902</td>\n",
       "      <td>-1.969954</td>\n",
       "      <td>-2.328378</td>\n",
       "      <td>-2.758960</td>\n",
       "      <td>3.087458</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24497</th>\n",
       "      <td>49</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>762.685387</td>\n",
       "      <td>745.553486</td>\n",
       "      <td>706.884007</td>\n",
       "      <td>695.708272</td>\n",
       "      <td>698.951357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621717</td>\n",
       "      <td>0.498336</td>\n",
       "      <td>0.356470</td>\n",
       "      <td>-0.131807</td>\n",
       "      <td>-0.426306</td>\n",
       "      <td>-0.748795</td>\n",
       "      <td>-1.031706</td>\n",
       "      <td>-1.339351</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24498</th>\n",
       "      <td>49</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>401.220638</td>\n",
       "      <td>416.688133</td>\n",
       "      <td>388.561449</td>\n",
       "      <td>390.436935</td>\n",
       "      <td>370.411933</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.801749</td>\n",
       "      <td>-2.120022</td>\n",
       "      <td>-2.410138</td>\n",
       "      <td>3.138034</td>\n",
       "      <td>2.751942</td>\n",
       "      <td>2.306627</td>\n",
       "      <td>1.868269</td>\n",
       "      <td>1.432071</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24499</th>\n",
       "      <td>49</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>753.160010</td>\n",
       "      <td>739.957431</td>\n",
       "      <td>724.996552</td>\n",
       "      <td>704.264865</td>\n",
       "      <td>701.806954</td>\n",
       "      <td>...</td>\n",
       "      <td>1.746490</td>\n",
       "      <td>1.586924</td>\n",
       "      <td>1.427713</td>\n",
       "      <td>1.118018</td>\n",
       "      <td>0.870126</td>\n",
       "      <td>0.650771</td>\n",
       "      <td>0.353386</td>\n",
       "      <td>0.054227</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24500 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label  AP1_Rssi  AP2_Rssi  AP3_Rssi  AP4_Rssi           0           1  \\\n",
       "0          1     -62.0     -72.0     -65.0     -54.0  919.592301  929.595611   \n",
       "1          1     -61.0     -73.0     -66.0     -56.0  698.204841  732.963846   \n",
       "2          1     -62.0     -72.0     -66.0     -55.0  745.268408  768.188128   \n",
       "3          1     -61.0     -73.0     -66.0     -55.0  830.278267  829.860832   \n",
       "4          1     -54.0     -72.0     -67.0     -55.0  906.099884  903.507056   \n",
       "...      ...       ...       ...       ...       ...         ...         ...   \n",
       "24495     49     -54.0     -64.0     -56.0     -58.0  397.615392  416.889674   \n",
       "24496     49     -55.0     -65.0     -56.0     -57.0  643.708785  646.260010   \n",
       "24497     49     -53.0     -63.0     -53.0     -56.0  762.685387  745.553486   \n",
       "24498     49     -53.0     -64.0     -55.0     -59.0  401.220638  416.688133   \n",
       "24499     49     -54.0     -65.0     -55.0     -59.0  753.160010  739.957431   \n",
       "\n",
       "                2           3           4  ...        88        89        90  \\\n",
       "0      877.760787  898.203763  851.400023  ... -1.387518 -1.581549 -1.708760   \n",
       "1      684.079674  694.257877  651.079872  ... -2.677159 -2.877730 -3.051501   \n",
       "2      706.606680  713.252410  681.482208  ...  0.176051 -0.063704 -0.251636   \n",
       "3      804.005597  796.492310  786.787138  ... -1.031820 -1.194379 -1.338067   \n",
       "4      910.843565  896.688352  892.235955  ... -0.445534 -0.593750 -0.783166   \n",
       "...           ...         ...         ...  ...       ...       ...       ...   \n",
       "24495  395.588170  413.019370  382.733589  ...  2.183710  2.005190  1.826107   \n",
       "24496  627.624888  621.498994  605.152873  ... -0.494557 -0.782703 -1.053078   \n",
       "24497  706.884007  695.708272  698.951357  ...  0.621717  0.498336  0.356470   \n",
       "24498  388.561449  390.436935  370.411933  ... -1.801749 -2.120022 -2.410138   \n",
       "24499  724.996552  704.264865  701.806954  ...  1.746490  1.586924  1.427713   \n",
       "\n",
       "             91        92        93        94        95    96     97  \n",
       "0     -2.080869 -2.287379 -2.467120 -2.666997 -2.982241 -50.0  136.0  \n",
       "1      2.738820  2.503722  2.256683  2.035376  1.737005 -49.0  148.0  \n",
       "2     -0.776139 -1.023850 -1.275624 -1.535994 -1.899522 -50.0  224.0  \n",
       "3     -1.666445 -1.878363 -2.100073 -2.369892 -2.666982 -51.0  136.0  \n",
       "4     -1.090942 -1.286103 -1.497279 -1.784787 -2.076610 -50.0  136.0  \n",
       "...         ...       ...       ...       ...       ...   ...    ...  \n",
       "24495  1.364322  1.150287  0.872978  0.573063  0.255977 -56.0  148.0  \n",
       "24496 -1.631902 -1.969954 -2.328378 -2.758960  3.087458 -59.0  136.0  \n",
       "24497 -0.131807 -0.426306 -0.748795 -1.031706 -1.339351 -58.0  136.0  \n",
       "24498  3.138034  2.751942  2.306627  1.868269  1.432071 -56.0  148.0  \n",
       "24499  1.118018  0.870126  0.650771  0.353386  0.054227 -58.0  136.0  \n",
       "\n",
       "[24500 rows x 103 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 假設以下兩個 DataFrame 已經就緒 ===\n",
    "# df_rssi: 包含 [\"Label\", ...] + RSSI 欄位\n",
    "# df_csi:  包含 [\"Label\", ...] + CSI 欄位\n",
    "\n",
    "# 取得兩邊都出現的所有 Label\n",
    "common_labels = sorted(set(df_final[\"Label\"].unique()) & set(csi[\"Label\"].unique()))\n",
    "\n",
    "merged_list = []\n",
    "\n",
    "for lb in common_labels:\n",
    "    # 1. 取出該 Label 的子集\n",
    "    sub_rssi = df_final[df_final[\"Label\"] == lb].reset_index(drop=True)\n",
    "    sub_csi  = csi[csi[\"Label\"] == lb].reset_index(drop=True)\n",
    "    \n",
    "    # 2. 檢查兩者長度是否一致\n",
    "    len_rssi = len(sub_rssi)\n",
    "    len_csi  = len(sub_csi)\n",
    "    \n",
    "    if len_rssi != len_csi:\n",
    "        print(f\"警告：Label={lb} 在 df_rssi 有 {len_rssi} 筆, df_csi 有 {len_csi} 筆，長度不同。\")\n",
    "        # 你可以選擇：略過、或僅取最短長度、或補齊…\n",
    "        # 這邊示範「取最小長度」來對齊\n",
    "        min_len = min(len_rssi, len_csi)\n",
    "        sub_rssi = sub_rssi.iloc[:min_len].reset_index(drop=True)\n",
    "        sub_csi  = sub_csi.iloc[:min_len].reset_index(drop=True)\n",
    "    \n",
    "    # 3. 逐列「貼合」兩個子 DataFrame (axis=1 即左右合併)\n",
    "    #    如果不想留重複的 Label 欄位，可以先丟掉 sub_csi 的 Label 欄位\n",
    "    sub_csi_dropped = sub_csi.drop(columns=[\"Label\"])\n",
    "    \n",
    "    # 合併\n",
    "    sub_merged = pd.concat([sub_rssi, sub_csi_dropped], axis=1)\n",
    "    \n",
    "    # 4. 把合併後的子 DataFrame 放進清單\n",
    "    merged_list.append(sub_merged)\n",
    "\n",
    "# 5. 最後把所有 Label 的結果上下堆起來\n",
    "df_merged_all = pd.concat(merged_list, ignore_index=True)\n",
    "\n",
    "# 檢查\n",
    "print(df_merged_all.shape)\n",
    "df_merged_all\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73bc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "rssi_columns = ['AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi']\n",
    "df_merged_all[rssi_columns] = df_merged_all[rssi_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c39e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_labels = df_merged_all['Label']\n",
    "csi = df_merged_all.drop(columns=['Label', 'AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi'])\n",
    "amp = csi.iloc[:,:48]\n",
    "phase = csi.iloc[:,48:-2]\n",
    "rssi = df_merged_all[['AP1_Rssi', 'AP2_Rssi', 'AP3_Rssi', 'AP4_Rssi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f78b4bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csi shape: (24500, 4)\n",
      "amp shape: (24500, 48)\n"
     ]
    }
   ],
   "source": [
    "print(\"csi shape:\", rssi.shape)\n",
    "print(\"amp shape:\", amp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b13ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(amp)\n",
    "amp1 = amp.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c27bc6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 指定不訓練的 label（測試點）\n",
    "#第一組 test_labels = [4,8,43,47,24,29]\n",
    "#第二組 \n",
    "test_labels = [3, 6, 9, 48, 45, 42, 23, 29, 26]\n",
    "# 1️⃣ 篩出 test 與 train+val index\n",
    "test_idx = rp_labels[rp_labels.isin(test_labels)].index\n",
    "trainval_idx = rp_labels[~rp_labels.isin(test_labels)].index\n",
    "trainval_labels = rp_labels.loc[trainval_idx]\n",
    "\n",
    "# 2️⃣ 從 trainval 中 stratified 切出 validation（例如 15% 作 val）\n",
    "train_idx, val_idx = train_test_split(\n",
    "    trainval_idx,\n",
    "    test_size=0.15,\n",
    "    stratify=trainval_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3️⃣ 根據 index 切資料\n",
    "amp_train = amp.loc[train_idx]\n",
    "rssi_train = rssi.loc[train_idx]\n",
    "y_train = rp_labels.loc[train_idx]\n",
    "\n",
    "amp_val = amp.loc[val_idx]\n",
    "rssi_val = rssi.loc[val_idx]\n",
    "y_val = rp_labels.loc[val_idx]\n",
    "\n",
    "amp_test = amp.loc[test_idx]\n",
    "rssi_test = rssi.loc[test_idx]\n",
    "y_test = rp_labels.loc[test_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b25e37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 先定義所有可能的 label（1~49）\n",
    "all_labels = np.array(sorted(rp_labels.unique())).reshape(-1, 1)\n",
    "\n",
    "# 初始化 OneHotEncoder，指定 categories 為全部 49 類\n",
    "encoder = OneHotEncoder(categories=[all_labels.ravel()], sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# 用 full label space fit\n",
    "encoder.fit(all_labels)\n",
    "\n",
    "# 分別轉換\n",
    "y_train_oh = encoder.transform(np.array(y_train).reshape(-1, 1))\n",
    "y_val_oh   = encoder.transform(np.array(y_val).reshape(-1, 1))\n",
    "y_test_oh  = encoder.transform(np.array(y_test).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a96a7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_oh shape: (18275, 49)\n",
      "y_val_oh shape: (3225, 49)\n",
      "y_test_oh shape: (3000, 49)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train_oh shape:\", y_train_oh.shape)\n",
    "print(\"y_val_oh shape:\", y_val_oh.shape)\n",
    "print(\"y_test_oh shape:\", y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f654496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 Dataset 和 DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = CSIRSSIDataset(np.array(amp_train), np.array(rssi_train), y_train_oh, augment=True, csi_noise_std=0.00, rssi_mask_prob=0.05)\n",
    "val_dataset = CSIRSSIDataset(np.array(amp_val),np.array(rssi_val), y_val_oh)\n",
    "test_dataset = CSIRSSIDataset(np.array(amp_test), np.array(rssi_test), y_test_oh)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "704c5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 假設模型已經定義好\n",
    "class CSIRSSI_Classifier_BN(nn.Module):\n",
    "    def __init__(self, num_classes=49, rssi_dim=4):\n",
    "        super(CSIRSSI_Classifier_BN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        self.flatten_dim = 128 * 12\n",
    "        self.fc1   = nn.Linear(self.flatten_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2   = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc_rssi1 = nn.Linear(rssi_dim, 128)\n",
    "        self.bn_rssi1 = nn.BatchNorm1d(128)\n",
    "        self.dropout_rssi1 = nn.Dropout(0.5)\n",
    "        self.fc_rssi2 = nn.Linear(128, 32)\n",
    "        self.bn_rssi2 = nn.BatchNorm1d(32)\n",
    "        self.dropout_rssi2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc_fusion = nn.Linear(64 + 32, 64)\n",
    "        self.dropout_fusion = nn.Dropout(0.3)\n",
    "        self.fc_class = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, csi_input, rssi_input):\n",
    "        if csi_input.dim() == 2:\n",
    "            csi_input = csi_input.unsqueeze(1)\n",
    "        x = F.relu(self.bn1(self.conv1(csi_input)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        csi_feat = F.relu(self.fc2(x))\n",
    "        csi_feat = self.dropout2(csi_feat)\n",
    "\n",
    "        rssi_feat = F.relu(self.bn_rssi1(self.fc_rssi1(rssi_input)))\n",
    "        rssi_feat = self.dropout_rssi1(rssi_feat)\n",
    "        rssi_feat = F.relu(self.bn_rssi2(self.fc_rssi2(rssi_feat)))\n",
    "        rssi_feat = self.dropout_rssi2(rssi_feat)\n",
    "\n",
    "        fusion = torch.cat([csi_feat, rssi_feat], dim=1)\n",
    "        fusion = F.relu(self.fc_fusion(fusion))\n",
    "        fusion = self.dropout_fusion(fusion)\n",
    "\n",
    "        class_out = self.fc_class(fusion)\n",
    "        return class_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c3057d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcs/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失函數\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 優化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 學習率調整器\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2513b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/1 ===\n",
      "✅ Run 1: Acc = 0.00%, MDE = 3.0372\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "num_runs = 1\n",
    "epochs = 300\n",
    "patience = 20\n",
    "\n",
    "# ===== 你的模型 CSIRSSI_Classifier_BN 定義在這裡（略） =====\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train_loader, val_loader, test_loader\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# COORDINATES = {1: (x1, y1), ..., 49: (xn, yn)}\n",
    "# compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "\n",
    "\n",
    "def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "    coordinates: dict, label -> (x, y)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        # 取出對應的座標\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "            print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        # 計算歐氏距離\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors) , errors\n",
    "\n",
    "COORDINATES = {\n",
    "    # 下邊界 (1-10 和 40-31)\n",
    "    1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "    36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "    # 左邊界 (1-11)\n",
    "    2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "    6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "    # 上邊界 (11-21)\n",
    "    12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "    16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "    20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "    # 右邊界 (21-31)\n",
    "    22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "    26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "    # 中間點 (41-49)\n",
    "    41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "    44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "    47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "}\n",
    "\n",
    "def labels_to_coords(label_tensor, coord_dict):\n",
    "    coords = []\n",
    "    for label in label_tensor:\n",
    "        # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "        coords.append(coord_dict[label.item() + 1])\n",
    "    return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)\n",
    "\n",
    "test_accs = []\n",
    "test_mdes = []\n",
    "all_run_errors = []\n",
    "\n",
    "for run in range(1, num_runs + 1):\n",
    "    print(f\"\\n=== Run {run}/{num_runs} ===\")\n",
    "\n",
    "    model = CSIRSSI_Classifier_BN(num_classes=49).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15)\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for csi_inputs, rssi_inputs, labels in train_loader:\n",
    "            csi_inputs, rssi_inputs, labels = csi_inputs.to(device), rssi_inputs.to(device), labels.to(device)\n",
    "            target_class = torch.argmax(labels, dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            class_out = model(csi_inputs, rssi_inputs)\n",
    "            loss = criterion_cls(class_out, target_class)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 驗證\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for csi_inputs, rssi_inputs, labels in val_loader:\n",
    "                csi_inputs, rssi_inputs, labels = csi_inputs.to(device), rssi_inputs.to(device), labels.to(device)\n",
    "                target_class = torch.argmax(labels, dim=1)\n",
    "                class_out = model(csi_inputs, rssi_inputs)\n",
    "                val_loss += criterion_cls(class_out, target_class).item() * csi_inputs.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "\n",
    "    # 測試\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for csi_inputs, rssi_inputs, labels in test_loader:\n",
    "            csi_inputs, rssi_inputs, labels = csi_inputs.to(device), rssi_inputs.to(device), labels.to(device)\n",
    "            target_class = torch.argmax(labels, dim=1)\n",
    "            class_out = model(csi_inputs, rssi_inputs)\n",
    "            pred = torch.argmax(class_out, dim=1)\n",
    "            all_pred.extend(pred.cpu().numpy())\n",
    "            all_true.extend(target_class.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(all_true) + 1\n",
    "    y_pred = np.array(all_pred) + 1\n",
    "    acc = 100 * np.mean(y_true == y_pred)\n",
    "    mde, errors = compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "\n",
    "    test_accs.append(acc)\n",
    "    test_mdes.append(mde)\n",
    "    all_run_errors.append(errors)\n",
    "    print(f\"✅ Run {run}: Acc = {acc:.2f}%, MDE = {mde:.4f}\")\n",
    "\n",
    "# 儲存 summary 結果\n",
    "os.makedirs(\"repeat_for_zero_shot/00\", exist_ok=True)\n",
    "df = pd.DataFrame({\n",
    "    \"run\": list(range(1, num_runs+1)),\n",
    "    \"accuracy\": test_accs,\n",
    "    \"mde\": test_mdes\n",
    "})\n",
    "df.to_csv(\"repeat_for_zero_shot/00/csirssi_cls_results00_errorK2.csv\", index=False)\n",
    "\n",
    "# 儲存所有 error（長條格式）\n",
    "error_records = []\n",
    "for run_idx, errors in enumerate(all_run_errors):\n",
    "    for sample_idx, e in enumerate(errors):\n",
    "        error_records.append({\n",
    "            \"run\": run_idx + 1,\n",
    "            \"sample_idx\": sample_idx + 1,\n",
    "            \"error\": e\n",
    "        })\n",
    "df_errors = pd.DataFrame(error_records)\n",
    "df_errors.to_csv(\"repeat_for_zero_shot/00/csirssi_cls_all_errors00K2.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b48c7dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 讀取 error 檔\n",
    "df = pd.read_csv(\"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_CNN/repeat_for_zero_shot/00/csirssi_cls_all_errors00K.csv\")\n",
    "df2 = pd.read_csv(\"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/model_CNN/repeat_for_zero_shot/0.9/all_errors.csv\")\n",
    "errors = df[\"error\"].values\n",
    "errors2 = df2[\"error\"].values\n",
    "# 1. 全部 error 的 CDF\n",
    "sorted_errors = np.sort(errors)\n",
    "cdf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\n",
    "sorted_errors2 = np.sort(errors2)\n",
    "cdf2 = np.arange(1, len(sorted_errors2) + 1) / len(sorted_errors2)\n",
    "# 2. Zoom-in：只看 Y=0.99~1.0 區間\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(sorted_errors, cdf, label=\"CDF (Zoom 0.99~1.0)\")\n",
    "plt.plot(sorted_errors2, cdf2, label=\"CDF (Zoom 0.99~1.0)\")\n",
    "plt.xlabel(\"Localization Error (m)\")\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"CDF of Localization Error (Zoomed)\")\n",
    "#plt.ylim(0.995, 1.00)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5c38453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型摘要:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CSIRSSI_DualHead_BN                      [1, 49]                   --\n",
       "├─Conv1d: 1-1                            [1, 64, 48]               256\n",
       "├─BatchNorm1d: 1-2                       [1, 64, 48]               128\n",
       "├─MaxPool1d: 1-3                         [1, 64, 24]               --\n",
       "├─Conv1d: 1-4                            [1, 128, 24]              24,704\n",
       "├─BatchNorm1d: 1-5                       [1, 128, 24]              256\n",
       "├─MaxPool1d: 1-6                         [1, 128, 12]              --\n",
       "├─Linear: 1-7                            [1, 128]                  196,736\n",
       "├─Dropout: 1-8                           [1, 128]                  --\n",
       "├─Linear: 1-9                            [1, 64]                   8,256\n",
       "├─Dropout: 1-10                          [1, 64]                   --\n",
       "├─Linear: 1-11                           [1, 128]                  640\n",
       "├─BatchNorm1d: 1-12                      [1, 128]                  256\n",
       "├─Dropout: 1-13                          [1, 128]                  --\n",
       "├─Linear: 1-14                           [1, 32]                   4,128\n",
       "├─BatchNorm1d: 1-15                      [1, 32]                   64\n",
       "├─Dropout: 1-16                          [1, 32]                   --\n",
       "├─Linear: 1-17                           [1, 64]                   6,208\n",
       "├─Dropout: 1-18                          [1, 64]                   --\n",
       "├─Linear: 1-19                           [1, 49]                   3,185\n",
       "├─Linear: 1-20                           [1, 2]                    130\n",
       "==========================================================================================\n",
       "Total params: 244,947\n",
       "Trainable params: 244,947\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.83\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.10\n",
       "Params size (MB): 0.98\n",
       "Estimated Total Size (MB): 1.08\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary  # torchinfo 可用來顯示多輸入模型摘要\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------\n",
    "# 模型定義：CSIRSSI_DualHead\n",
    "# -----------------------\n",
    "class CSIRSSI_DualHead_BN(nn.Module):\n",
    "    def __init__(self, num_classes=49, rssi_dim=4):\n",
    "        super(CSIRSSI_DualHead_BN, self).__init__()\n",
    "        # ---- CSI 分支 (CNN) ---\n",
    "        # 假設輸入 CSI shape 為 (batch, 1, 48)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # 輸入長度 48 → 經過兩次 pooling → 48/2=24，再 24/2=12\n",
    "        self.flatten_dim = 128 * 12\n",
    "        \n",
    "        self.fc1   = nn.Linear(self.flatten_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2   = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        # 此時 CSI 分支輸出 64 維特徵\n",
    "        \n",
    "        # ---- RSSI 分支 (MLP) ----\n",
    "        self.fc_rssi1 = nn.Linear(rssi_dim, 128)\n",
    "        self.bn_rssi1 = nn.BatchNorm1d(128)\n",
    "        self.dropout_rssi1 = nn.Dropout(0.5)\n",
    "        self.fc_rssi2 = nn.Linear(128, 32)\n",
    "        self.bn_rssi2 = nn.BatchNorm1d(32)\n",
    "        self.dropout_rssi2 = nn.Dropout(0.5)\n",
    "        # RSSI 分支輸出 32 維特徵\n",
    "        \n",
    "        # ---- 融合層 ----\n",
    "        # 將 CSI (64-d) 與 RSSI (32-d) 連接 → 96-d\n",
    "        self.fc_fusion = nn.Linear(64+32, 64)\n",
    "        self.dropout_fusion = nn.Dropout(0.3)\n",
    "        \n",
    "        # ---- 雙輸出頭 ----\n",
    "        # 分類頭：輸出 num_classes 個類別的 logits\n",
    "        self.fc_class = nn.Linear(64, num_classes)\n",
    "        # 回歸頭：輸出 2 個數值 (X, Y)\n",
    "        self.fc_reg = nn.Linear(64, 2)\n",
    "    \n",
    "    def forward(self, csi_input, rssi_input):\n",
    "        # CSI 分支\n",
    "        # 如果輸入為 (batch, 48)，則擴展成 (batch, 1, 48)\n",
    "        if csi_input.dim() == 2:\n",
    "            csi_input = csi_input.unsqueeze(1)\n",
    "        x = F.relu(self.bn1(self.conv1(csi_input)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten → (batch, flatten_dim)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        csi_feat = F.relu(self.fc2(x))\n",
    "        csi_feat = self.dropout2(csi_feat)\n",
    "        \n",
    "        # RSSI 分支\n",
    "        rssi_feat = F.relu(self.bn_rssi1(self.fc_rssi1(rssi_input)))\n",
    "        rssi_feat = self.dropout_rssi1(rssi_feat)\n",
    "        rssi_feat = F.relu(self.bn_rssi2(self.fc_rssi2(rssi_feat)))\n",
    "        rssi_feat = self.dropout_rssi2(rssi_feat)\n",
    "        \n",
    "        # 融合特徵\n",
    "        fusion = torch.cat([csi_feat, rssi_feat], dim=1)  # (batch, 96)\n",
    "        fusion = F.relu(self.fc_fusion(fusion))\n",
    "        fusion = self.dropout_fusion(fusion)\n",
    "        \n",
    "        # 雙輸出頭\n",
    "        class_out = self.fc_class(fusion)  # 分類輸出 (batch, num_classes)\n",
    "        reg_out = self.fc_reg(fusion)       # 回歸輸出 (batch, 2)\n",
    "        \n",
    "        return class_out, reg_out\n",
    "\n",
    "# -----------------------\n",
    "# 模型初始化與摘要\n",
    "# -----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CSIRSSI_DualHead_BN(num_classes=49, rssi_dim=4).to(device)\n",
    "\n",
    "print(\"模型摘要:\")\n",
    "summary(model, input_data=(torch.randn(1, 1, 48).to(device), torch.randn(1, 4).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ab80a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Alpha = 0.1] 開始 1 次訓練\n",
      "Run 1/1 - Alpha = 0.1\n",
      "✅ Run 1: Acc = 0.00%, MDE = 3.1252\n",
      "📁 Results & all errors saved to repeat_for_zero_shot/0.1\n",
      "\n",
      "[Alpha = 0.2] 開始 1 次訓練\n",
      "Run 1/1 - Alpha = 0.2\n",
      "✅ Run 1: Acc = 0.00%, MDE = 3.5973\n",
      "📁 Results & all errors saved to repeat_for_zero_shot/0.2\n",
      "\n",
      "[Alpha = 0.3] 開始 1 次訓練\n",
      "Run 1/1 - Alpha = 0.3\n",
      "✅ Run 1: Acc = 0.00%, MDE = 3.6446\n",
      "📁 Results & all errors saved to repeat_for_zero_shot/0.3\n",
      "\n",
      "[Alpha = 0.4] 開始 1 次訓練\n",
      "Run 1/1 - Alpha = 0.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m csi_inputs, rssi_inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 24\u001b[0m     csi_inputs, rssi_inputs, labels \u001b[38;5;241m=\u001b[39m csi_inputs\u001b[38;5;241m.\u001b[39mto(device), rssi_inputs\u001b[38;5;241m.\u001b[39mto(device), \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     target_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alphas = [round(a, 1) for a in np.arange(0.1, 1.01, 0.1)]\n",
    "num_runs = 1\n",
    "epochs = 300\n",
    "patience = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion_reg = nn.MSELoss()\n",
    "for alpha in alphas:\n",
    "    test_accs = []\n",
    "    test_mdes = []\n",
    "    all_run_errors = []\n",
    "\n",
    "    print(f\"\\n[Alpha = {alpha:.1f}] 開始 {num_runs} 次訓練\")\n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"Run {run}/{num_runs} - Alpha = {alpha:.1f}\")\n",
    "        model = CSIRSSI_DualHead_BN(num_classes=49, rssi_dim=4).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15)\n",
    "        best_val_loss = float('inf')\n",
    "        counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for csi_inputs, rssi_inputs, labels in train_loader:\n",
    "                csi_inputs, rssi_inputs, labels = csi_inputs.to(device), rssi_inputs.to(device), labels.to(device)\n",
    "                target_class = torch.argmax(labels, dim=1)\n",
    "                optimizer.zero_grad()\n",
    "                class_out, reg_out = model(csi_inputs, rssi_inputs)\n",
    "                loss_cls = criterion(class_out, target_class)\n",
    "                loss_reg = criterion_reg(reg_out, labels_to_coords(target_class, COORDINATES))\n",
    "                loss = loss_cls + alpha * loss_reg\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for csi_inputs, rssi_inputs, labels in val_loader:\n",
    "                    csi_inputs, rssi_inputs, labels = csi_inputs.to(device), rssi_inputs.to(device), labels.to(device)\n",
    "                    target_class = torch.argmax(labels, dim=1)\n",
    "                    class_out, reg_out = model(csi_inputs, rssi_inputs)\n",
    "                    loss_cls = criterion(class_out, target_class)\n",
    "                    loss_reg = criterion_reg(reg_out, labels_to_coords(target_class, COORDINATES))\n",
    "                    val_loss += (loss_cls + alpha * loss_reg).item() * csi_inputs.size(0)\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    break\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        all_true, all_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for csi_inputs, rssi_inputs, labels in test_loader:\n",
    "                csi_inputs, rssi_inputs, labels = csi_inputs.to(device), rssi_inputs.to(device), labels.to(device)\n",
    "                target_class = torch.argmax(labels, dim=1)\n",
    "                class_out, _ = model(csi_inputs, rssi_inputs)\n",
    "                pred = torch.argmax(class_out, dim=1)\n",
    "                all_pred.extend(pred.cpu().numpy())\n",
    "                all_true.extend(target_class.cpu().numpy())\n",
    "\n",
    "        y_true = np.array(all_true) + 1\n",
    "        y_pred = np.array(all_pred) + 1\n",
    "        acc = 100 * np.mean(y_true == y_pred)\n",
    "        mde, errors = compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "\n",
    "        test_accs.append(acc)\n",
    "        test_mdes.append(mde)\n",
    "        all_run_errors.append(errors)\n",
    "        print(f\"✅ Run {run}: Acc = {acc:.2f}%, MDE = {mde:.4f}\")\n",
    "\n",
    "    # 儲存結果\n",
    "    folder_name = f\"repeat_for_zero_shot/{alpha:.1f}\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    df_runs = pd.DataFrame({\n",
    "        'run': list(range(1, num_runs + 1)),\n",
    "        'accuracy': test_accs,\n",
    "        'mde': test_mdes\n",
    "    })\n",
    "    df_runs.to_csv(f\"{folder_name}/summaryK2.csv\", index=False)\n",
    "\n",
    "    error_records = []\n",
    "    for run_idx, errors in enumerate(all_run_errors):\n",
    "        for sample_idx, e in enumerate(errors):\n",
    "            error_records.append({\n",
    "                \"run\": run_idx + 1,\n",
    "                \"sample_idx\": sample_idx + 1,\n",
    "                \"error\": e\n",
    "            })\n",
    "    df_errors = pd.DataFrame(error_records)\n",
    "    df_errors.to_csv(f\"{folder_name}/all_errorsK2.csv\", index=False)\n",
    "    print(\"📁 Results & all errors saved to\", folder_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
