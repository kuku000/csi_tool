{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d527e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from csidataset import *\n",
    "import data_loader\n",
    "from data_loader import *\n",
    "sys.path.append(\"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool\")\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5797966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 讀取成功，資料維度： (19649, 53)\n",
      "✅ [amp] 切出來： [618.80934059 592.62551413 566.35059813 537.837336   496.88328609]\n",
      "✅ [amp] 原始 df： [618.80934059 592.62551413 566.35059813 537.837336   496.88328609]\n",
      "✅ [label] 切出來： 4\n",
      "✅ [label] 原始 df： 4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 路徑\n",
    "load_path = \"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/csi_dataset/rssi/combined_csi_rssi_slim2.4G.csv\"\n",
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv(load_path)\n",
    "print(\"✅ 讀取成功，資料維度：\", df.shape)\n",
    "\n",
    "# 保留 index 方便對照\n",
    "df[\"orig_index\"] = df.index\n",
    "\n",
    "# 特徵分割\n",
    "amp = df.iloc[:, 0:48].values\n",
    "labels = df[\"Label\"].values\n",
    "orig_idx = df[\"orig_index\"].values\n",
    "\n",
    "# 切 train / temp\n",
    "amp_train, amp_temp, y_train, y_temp, idx_train, idx_temp = train_test_split(\n",
    "    amp, labels, orig_idx, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 切 val / test\n",
    "amp_val, amp_test,y_val, y_test, idx_val, idx_test = train_test_split(\n",
    "    amp_temp, y_temp, idx_temp, test_size=2/3, random_state=42\n",
    ")\n",
    "\n",
    "# 檢查一筆對不對齊\n",
    "i = 0\n",
    "print(\"✅ [amp] 切出來：\", amp_train[i][:5])\n",
    "print(\"✅ [amp] 原始 df：\", df.iloc[int(idx_train[i]), 0:5].values)\n",
    "\n",
    "\n",
    "print(\"✅ [label] 切出來：\", y_train[i])\n",
    "print(\"✅ [label] 原始 df：\", df.iloc[int(idx_train[i])][\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d229b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_oh = encoder.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_val_oh = encoder.transform(np.array(y_val).reshape(-1, 1))\n",
    "y_test_oh = encoder.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdf1e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 Dataset 和 DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = CSIDataset(amp_train, y_train_oh)\n",
    "val_dataset = CSIDataset(amp_val, y_val_oh)\n",
    "test_dataset = CSIDataset(amp_test, y_test_oh)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03ef67",
   "metadata": {},
   "source": [
    "# 2.4 G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bfb9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "    coordinates: dict, label -> (x, y)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        # 取出對應的座標\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "            print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        # 計算歐氏距離\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors) , errors\n",
    "\n",
    "COORDINATES = {\n",
    "    # 下邊界 (1-10 和 40-31)\n",
    "    1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "    36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "    # 左邊界 (1-11)\n",
    "    2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "    6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "    # 上邊界 (11-21)\n",
    "    12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "    16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "    20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "    # 右邊界 (21-31)\n",
    "    22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "    26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "    # 中間點 (41-49)\n",
    "    41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "    44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "    47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "}\n",
    "\n",
    "def labels_to_coords(label_tensor, coord_dict):\n",
    "    coords = []\n",
    "    for label in label_tensor:\n",
    "        # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "        coords.append(coord_dict[label.item() + 1])\n",
    "    return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2c7564b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 64, 48]             256\n",
      "       BatchNorm1d-2               [-1, 64, 48]             128\n",
      "         MaxPool1d-3               [-1, 64, 24]               0\n",
      "            Conv1d-4              [-1, 128, 24]          24,704\n",
      "       BatchNorm1d-5              [-1, 128, 24]             256\n",
      "         MaxPool1d-6              [-1, 128, 12]               0\n",
      "            Linear-7                  [-1, 128]         196,736\n",
      "           Dropout-8                  [-1, 128]               0\n",
      "            Linear-9                   [-1, 64]           8,256\n",
      "          Dropout-10                   [-1, 64]               0\n",
      "           Linear-11                   [-1, 49]           3,185\n",
      "================================================================\n",
      "Total params: 233,521\n",
      "Trainable params: 233,521\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 0.89\n",
      "Estimated Total Size (MB): 1.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=49):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.flatten_dim = 128 * 12  # 48 -> 24 -> 12 after pooling\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input is in the shape (batch_size, channels, length)\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        if x.shape[1] != 1:\n",
    "            x = x.permute(0, 2, 1)  # (batch_size, 1, 48)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = CNNClassifier(num_classes=49).to(device)\n",
    "\n",
    "# Print model summary\n",
    "summary(model, input_size=(1, 48))  # Input shape: (channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8cb2f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcs/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失函數\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 優化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 學習率調整器\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc2862b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/5 ===\n",
      "✅ Run 1: Acc = 96.46%, MDE = 0.1684\n",
      "\n",
      "=== Run 2/5 ===\n",
      "✅ Run 2: Acc = 96.62%, MDE = 0.1536\n",
      "\n",
      "=== Run 3/5 ===\n",
      "✅ Run 3: Acc = 96.51%, MDE = 0.1638\n",
      "\n",
      "=== Run 4/5 ===\n",
      "✅ Run 4: Acc = 96.44%, MDE = 0.1711\n",
      "\n",
      "=== Run 5/5 ===\n",
      "✅ Run 5: Acc = 96.21%, MDE = 0.1811\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "    coordinates: dict, label -> (x, y)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        # 取出對應的座標\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "            print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        # 計算歐氏距離\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors) , errors\n",
    "\n",
    "COORDINATES = {\n",
    "    # 下邊界 (1-10 和 40-31)\n",
    "    1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "    36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "    # 左邊界 (1-11)\n",
    "    2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "    6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "    # 上邊界 (11-21)\n",
    "    12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "    16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "    20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "    # 右邊界 (21-31)\n",
    "    22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "    26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "    # 中間點 (41-49)\n",
    "    41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "    44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "    47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "}\n",
    "\n",
    "def labels_to_coords(label_tensor, coord_dict):\n",
    "    coords = []\n",
    "    for label in label_tensor:\n",
    "        # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "        coords.append(coord_dict[label.item() + 1])\n",
    "    return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ...你的 CNNClassifier、COORDINATES、compute_mean_distance_error ...\n",
    "\n",
    "num_runs = 5\n",
    "epochs = 200\n",
    "patience = 20\n",
    "\n",
    "test_accs = []\n",
    "test_mdes = []\n",
    "all_run_errors = []\n",
    "\n",
    "for run in range(1, num_runs + 1):\n",
    "    print(f\"\\n=== Run {run}/{num_runs} ===\")\n",
    "    model = CNNClassifier(num_classes=49).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for csi_inputs, labels in train_loader:\n",
    "            csi_inputs, labels = csi_inputs.to(device), labels.to(device)\n",
    "            target_class = torch.argmax(labels, dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            class_out = model(csi_inputs)\n",
    "            loss = criterion(class_out, target_class)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for csi_inputs, labels in val_loader:\n",
    "                csi_inputs, labels = csi_inputs.to(device), labels.to(device)\n",
    "                target_class = torch.argmax(labels, dim=1)\n",
    "                class_out = model(csi_inputs)\n",
    "                val_loss += criterion(class_out, target_class).item() * csi_inputs.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for csi_inputs, labels in test_loader:\n",
    "            csi_inputs, labels = csi_inputs.to(device), labels.to(device)\n",
    "            target_class = torch.argmax(labels, dim=1)\n",
    "            class_out = model(csi_inputs)\n",
    "            pred = torch.argmax(class_out, dim=1)\n",
    "            all_pred.extend(pred.cpu().numpy())\n",
    "            all_true.extend(target_class.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(all_true) + 1\n",
    "    y_pred = np.array(all_pred) + 1\n",
    "    acc = 100 * np.mean(y_true == y_pred)\n",
    "    mde, error = compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "    test_accs.append(acc)\n",
    "    test_mdes.append(mde)\n",
    "    all_run_errors.append(error)\n",
    "\n",
    "    print(f\"✅ Run {run}: Acc = {acc:.2f}%, MDE = {mde:.4f}\")\n",
    "\n",
    "os.makedirs(\"repeat_2_4_copy/00\", exist_ok=True)\n",
    "df = pd.DataFrame({\n",
    "    \"run\": list(range(1, num_runs+1)),\n",
    "    \"accuracy\": test_accs,\n",
    "    \"mde\": test_mdes\n",
    "})\n",
    "df.to_csv(\"repeat_2_4_copy/00/csicls_results00_b2.csv\", index=False)\n",
    "\n",
    "# 儲存所有 error（長條格式）\n",
    "errors_flat = []\n",
    "for run_idx, errors in enumerate(all_run_errors):\n",
    "    for sample_idx, e in enumerate(errors):\n",
    "        errors_flat.append({\n",
    "            \"run\": run_idx + 1,\n",
    "            \"sample_idx\": sample_idx + 1,\n",
    "            \"error\": e\n",
    "        })\n",
    "df_errors = pd.DataFrame(errors_flat)\n",
    "df_errors.to_csv(\"repeat_2_4_copy/00/csicls_all_errors00_b2.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6b95a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_DualHead(nn.Module):\n",
    "    def __init__(self, num_classes=49, regression_dim=2):\n",
    "        super(CNN_DualHead, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.flatten_dim = 128 * 12  # 48 -> 24 -> 12 after pooling\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        # Two heads: classification & regression\n",
    "        self.class_head = nn.Linear(64, num_classes)     # 分類 head\n",
    "        self.reg_head = nn.Linear(64, regression_dim)    # 回歸 head (預設 2 維)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        if x.shape[1] != 1:\n",
    "            x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        class_out = self.class_head(x)  # 分類輸出 (logits)\n",
    "        reg_out = self.reg_head(x)      # 回歸輸出 (通常 2 維)\n",
    "\n",
    "        return class_out, reg_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "252373ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Alpha = 0.1]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 96.56%, MDE = 0.1424\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 97.10%, MDE = 0.1326\n",
      "Run 3/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m     loss_reg \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(reg_out, labels_to_coords(target, COORDINATES))\n\u001b[1;32m     87\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_cls \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m loss_reg\n\u001b[0;32m---> 89\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(); loss\u001b[38;5;241m.\u001b[39mbackward(); optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     91\u001b[0m model\u001b[38;5;241m.\u001b[39meval(); val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "\n",
    "def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "    coordinates: dict, label -> (x, y)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        # 取出對應的座標\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "            print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        # 計算歐氏距離\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors) , errors\n",
    "\n",
    "COORDINATES = {\n",
    "    # 下邊界 (1-10 和 40-31)\n",
    "    1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "    36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "    # 左邊界 (1-11)\n",
    "    2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "    6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "    # 上邊界 (11-21)\n",
    "    12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "    16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "    20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "    # 右邊界 (21-31)\n",
    "    22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "    26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "    # 中間點 (41-49)\n",
    "    41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "    44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "    47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "}\n",
    "\n",
    "def labels_to_coords(label_tensor, coord_dict):\n",
    "    coords = []\n",
    "    for label in label_tensor:\n",
    "        # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "        coords.append(coord_dict[label.item() + 1])\n",
    "    return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "alphas   = np.arange(0.1, 1.1, 0.1)\n",
    "num_runs = 5\n",
    "epochs   = 200\n",
    "patience = 20\n",
    "\n",
    "summary_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    run_acc, run_mde = [], []\n",
    "    all_run_errors = []\n",
    "\n",
    "    print(f\"\\n[Alpha = {alpha:.1f}]  Start {num_runs} runs\")\n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"Run {run}/{num_runs}\")\n",
    "        model = CNN_DualHead(num_classes=49).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.5, patience=15)\n",
    "        best_val, wait = float('inf'), 0\n",
    "        best_state = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for csi_x, labels in train_loader:\n",
    "                csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "                target = torch.argmax(labels, 1)\n",
    "\n",
    "                cls_out, reg_out = model(csi_x)\n",
    "                loss_cls = nn.CrossEntropyLoss()(cls_out, target)\n",
    "                loss_reg = nn.MSELoss()(reg_out, labels_to_coords(target, COORDINATES))\n",
    "                loss = loss_cls + alpha * loss_reg\n",
    "\n",
    "                optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "\n",
    "            model.eval(); val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for csi_x, labels in val_loader:\n",
    "                    csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "                    target = torch.argmax(labels, 1)\n",
    "                    cls_out, reg_out = model(csi_x)\n",
    "                    v_loss = nn.CrossEntropyLoss()(cls_out, target) \\\n",
    "                           + alpha * nn.MSELoss()(reg_out, labels_to_coords(target, COORDINATES))\n",
    "                    val_loss += v_loss.item() * csi_x.size(0)\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if val_loss < best_val:\n",
    "                best_val, wait = val_loss, 0\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    break\n",
    "\n",
    "        # 測試用最佳模型\n",
    "        model.load_state_dict(best_state)\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for csi_x, labels in test_loader:\n",
    "                csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "                target = torch.argmax(labels, 1)\n",
    "                cls_out, _ = model(csi_x)\n",
    "                pred = torch.argmax(cls_out, 1)\n",
    "                y_true.extend((target.cpu().numpy() + 1))   # 轉 1-index\n",
    "                y_pred.extend((pred.cpu().numpy()   + 1))\n",
    "\n",
    "        mde_mean, err_vec = compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "        run_acc.append(100 * np.mean(np.array(y_true) == np.array(y_pred)))\n",
    "        run_mde.append(mde_mean)\n",
    "        all_run_errors.append(err_vec)\n",
    "        print(f\"✅ Run {run}: Acc = {run_acc[-1]:.2f}%, MDE = {mde_mean:.4f}\")\n",
    "\n",
    "    # 每個 alpha 儲存完整誤差\n",
    "    alpha_id = int(round(alpha * 10))\n",
    "    folder   = f\"repeat_2_4_copy/{alpha_id:02d}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        'run':     range(1, num_runs + 1),\n",
    "        'accuracy':run_acc,\n",
    "        'mde':     run_mde,\n",
    "    }).to_csv(f\"{folder}/csi_cls_reg_results{alpha_id:02d}_b2.csv\", index=False)\n",
    "\n",
    "    # 儲存所有誤差（長條格式）\n",
    "    errors_flat = []\n",
    "    for run_idx, errors in enumerate(all_run_errors):\n",
    "        for sample_idx, e in enumerate(errors):\n",
    "            errors_flat.append({\n",
    "                \"run\": run_idx + 1,\n",
    "                \"sample_idx\": sample_idx + 1,\n",
    "                \"error\": e\n",
    "            })\n",
    "    pd.DataFrame(errors_flat).to_csv(f\"{folder}/csi_cls_reg_all_errors{alpha_id:02d}_b2.csv\", index=False)\n",
    "\n",
    "    summary_results.append({\n",
    "        'alpha':   alpha,\n",
    "        'avg_acc': np.mean(run_acc),\n",
    "        'avg_mde': np.mean(run_mde),\n",
    "    })\n",
    "\n",
    "# summary_results 匯出 summary 檔\n",
    "pd.DataFrame(summary_results).to_csv(\"repeat_2_4_copy/summary.csv\", index=False)\n",
    "print(\"\\n=== DONE ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#測試CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
