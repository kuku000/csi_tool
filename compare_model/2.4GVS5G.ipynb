{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d527e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from csidataset import *\n",
    "import data_loader\n",
    "from data_loader import *\n",
    "sys.path.append(\"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool\")\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5797966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 讀取成功，資料維度： (19649, 53)\n",
      "✅ [amp] 切出來： [618.80934059 592.62551413 566.35059813 537.837336   496.88328609]\n",
      "✅ [amp] 原始 df： [618.80934059 592.62551413 566.35059813 537.837336   496.88328609]\n",
      "✅ [label] 切出來： 4\n",
      "✅ [label] 原始 df： 4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 路徑\n",
    "load_path = \"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/csi_dataset/rssi/combined_csi_rssi_slim2.4G.csv\"\n",
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv(load_path)\n",
    "print(\"✅ 讀取成功，資料維度：\", df.shape)\n",
    "\n",
    "# 保留 index 方便對照\n",
    "df[\"orig_index\"] = df.index\n",
    "\n",
    "# 特徵分割\n",
    "amp = df.iloc[:, 0:48].values\n",
    "labels = df[\"Label\"].values\n",
    "orig_idx = df[\"orig_index\"].values\n",
    "\n",
    "# 切 train / temp\n",
    "amp_train, amp_temp, y_train, y_temp, idx_train, idx_temp = train_test_split(\n",
    "    amp, labels, orig_idx, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 切 val / test\n",
    "amp_val, amp_test,y_val, y_test, idx_val, idx_test = train_test_split(\n",
    "    amp_temp, y_temp, idx_temp, test_size=2/3, random_state=42\n",
    ")\n",
    "\n",
    "# 檢查一筆對不對齊\n",
    "i = 0\n",
    "print(\"✅ [amp] 切出來：\", amp_train[i][:5])\n",
    "print(\"✅ [amp] 原始 df：\", df.iloc[int(idx_train[i]), 0:5].values)\n",
    "\n",
    "\n",
    "print(\"✅ [label] 切出來：\", y_train[i])\n",
    "print(\"✅ [label] 原始 df：\", df.iloc[int(idx_train[i])][\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d229b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_oh = encoder.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_val_oh = encoder.transform(np.array(y_val).reshape(-1, 1))\n",
    "y_test_oh = encoder.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7db3b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "    coordinates: dict, label -> (x, y)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        # 取出對應的座標\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "            print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        # 計算歐氏距離\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors) , errors\n",
    "\n",
    "COORDINATES = {\n",
    "    # 下邊界 (1-10 和 40-31)\n",
    "    1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "    36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "    # 左邊界 (1-11)\n",
    "    2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "    6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "    # 上邊界 (11-21)\n",
    "    12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "    16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "    20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "    # 右邊界 (21-31)\n",
    "    22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "    26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "    # 中間點 (41-49)\n",
    "    41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "    44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "    47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "}\n",
    "\n",
    "def labels_to_coords(label_tensor, coord_dict):\n",
    "    coords = []\n",
    "    for label in label_tensor:\n",
    "        # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "        coords.append(coord_dict[label.item() + 1])\n",
    "    return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5447292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大 label: 49\n",
      "最小 label: 1\n"
     ]
    }
   ],
   "source": [
    "labels = np.argmax(y_test, axis=1) + 1\n",
    "\n",
    "print(\"最大 label:\", np.max(labels))\n",
    "print(\"最小 label:\", np.min(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45bf75db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假設 y_test 是 one-hot label, shape (N, 49)\n",
    "labels = np.argmax(y_test, axis=1) + 1  # 得到 1~49 的 label\n",
    "\n",
    "plt.hist(labels, bins=49, range=(1, 50), density=True, alpha=0.5, label='Predicted')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "144d8ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance error: 0.04648341079321986\n"
     ]
    }
   ],
   "source": [
    "mean_error, _ = compute_mean_distance_error(np.argmax(y_test, axis=1)+1, np.argmax(y_pred, axis=1)+1, COORDINATES)\n",
    "print(\"Mean distance error:\", mean_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03ef67",
   "metadata": {},
   "source": [
    "# 2.4 G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b48f5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12/07\n",
    "base_path2 = \"/media/mcs/1441ae67-d7cd-43e6-b028-169f78661a2f/kyle/csi_tool/csi_dataset/localization_phone/1207_phone/20MHz/csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8338b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_points2 = {}\n",
    "\n",
    "spacing = 0.6  # 每隔 0.6m\n",
    "\n",
    "for ref_id, coord in data_loader.COORDINATES.items():\n",
    "    folder_path2 = os.path.join(base_path2, f\"reference_point_{ref_id}.xlsx\")\n",
    "    reference_points2[folder_path2] = (ref_id, coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f177a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, rp_labels, coord_labels = load_data(reference_points2)\n",
    "amp_data = np.array(data.iloc[:, :48])  \n",
    "phase_data = np.array(data.iloc[:, 48:-2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "783b308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "one_hot_labels = encoder.fit_transform(np.array(rp_labels).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3b376ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_train, amp_temp, y_train, y_temp = train_test_split(amp_data, one_hot_labels, test_size=0.3, random_state=42)\n",
    "amp_val, amp_test, y_val, y_test = train_test_split(amp_temp, y_temp, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a51f9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3,metric='euclidean')\n",
    "knn.fit(amp_train, y_train)\n",
    "y_pred = knn.predict(amp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "991e7c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9169054441260746"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8bfb9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "    coordinates: dict, label -> (x, y)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        # 取出對應的座標\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "            print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        # 計算歐氏距離\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors) , errors\n",
    "\n",
    "COORDINATES = {\n",
    "    # 下邊界 (1-10 和 40-31)\n",
    "    1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "    36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "    # 左邊界 (1-11)\n",
    "    2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "    6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "    # 上邊界 (11-21)\n",
    "    12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "    16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "    20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "    # 右邊界 (21-31)\n",
    "    22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "    26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "    # 中間點 (41-49)\n",
    "    41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "    44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "    47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "}\n",
    "\n",
    "def labels_to_coords(label_tensor, coord_dict):\n",
    "    coords = []\n",
    "    for label in label_tensor:\n",
    "        # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "        coords.append(coord_dict[label.item() + 1])\n",
    "    return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f061e419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance error: 0.3730696423008712\n"
     ]
    }
   ],
   "source": [
    "mean_error, _ = compute_mean_distance_error(np.argmax(y_test, axis=1)+1, np.argmax(y_pred, axis=1)+1, COORDINATES)\n",
    "print(\"Mean distance error:\", mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc261ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 Dataset 和 DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = CSIDataset(amp_train, y_train)\n",
    "val_dataset = CSIDataset(amp_val, y_val)\n",
    "test_dataset = CSIDataset(amp_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c2c7564b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 64, 48]             256\n",
      "       BatchNorm1d-2               [-1, 64, 48]             128\n",
      "         MaxPool1d-3               [-1, 64, 24]               0\n",
      "            Conv1d-4              [-1, 128, 24]          24,704\n",
      "       BatchNorm1d-5              [-1, 128, 24]             256\n",
      "         MaxPool1d-6              [-1, 128, 12]               0\n",
      "            Linear-7                  [-1, 128]         196,736\n",
      "           Dropout-8                  [-1, 128]               0\n",
      "            Linear-9                   [-1, 64]           8,256\n",
      "          Dropout-10                   [-1, 64]               0\n",
      "           Linear-11                   [-1, 49]           3,185\n",
      "================================================================\n",
      "Total params: 233,521\n",
      "Trainable params: 233,521\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 0.89\n",
      "Estimated Total Size (MB): 1.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=49):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.flatten_dim = 128 * 12  # 48 -> 24 -> 12 after pooling\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input is in the shape (batch_size, channels, length)\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        if x.shape[1] != 1:\n",
    "            x = x.permute(0, 2, 1)  # (batch_size, 1, 48)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = CNNClassifier(num_classes=49).to(device)\n",
    "\n",
    "# Print model summary\n",
    "summary(model, input_size=(1, 48))  # Input shape: (channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a8cb2f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcs/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失函數\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 優化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 學習率調整器\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bc2862b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/5 ===\n",
      "✅ Run 1: Acc = 93.86%, MDE = 0.2684\n",
      "\n",
      "=== Run 2/5 ===\n",
      "✅ Run 2: Acc = 94.27%, MDE = 0.2446\n",
      "\n",
      "=== Run 3/5 ===\n",
      "✅ Run 3: Acc = 93.98%, MDE = 0.2517\n",
      "\n",
      "=== Run 4/5 ===\n",
      "✅ Run 4: Acc = 94.27%, MDE = 0.2448\n",
      "\n",
      "=== Run 5/5 ===\n",
      "✅ Run 5: Acc = 94.31%, MDE = 0.2479\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 你原本的 CNNClassifier (單 CSI 輸入) 定義（略）\n",
    "\n",
    "# COORDINATES, compute_mean_distance_error 你的定義照舊\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 你原本的 CNNClassifier (單 CSI 輸入) 定義（略）\n",
    "\n",
    "# COORDINATES, compute_mean_distance_error 你的定義照舊\n",
    "\n",
    "num_runs = 5\n",
    "epochs = 200\n",
    "patience = 20\n",
    "\n",
    "test_accs = []\n",
    "test_mdes = []\n",
    "all_run_errors = []\n",
    "for run in range(1, num_runs + 1):\n",
    "    print(f\"\\n=== Run {run}/{num_runs} ===\")\n",
    "    model = CNNClassifier(num_classes=49).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    # === 主要修改從這裡開始 ===\n",
    "    best_model_path = \"best_model_tmp_24.pth\"\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for csi_inputs, labels in train_loader:\n",
    "            csi_inputs, labels = csi_inputs.to(device), labels.to(device)\n",
    "            target_class = torch.argmax(labels, dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            class_out = model(csi_inputs)\n",
    "            loss = criterion(class_out, target_class)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 驗證\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for csi_inputs, labels in val_loader:\n",
    "                csi_inputs, labels = csi_inputs.to(device), labels.to(device)\n",
    "                target_class = torch.argmax(labels, dim=1)\n",
    "                class_out = model(csi_inputs)\n",
    "                val_loss += criterion(class_out, target_class).item() * csi_inputs.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "            # ---- 新增：儲存最佳模型 ----\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "    # === 主要修改到這裡結束 ===\n",
    "\n",
    "    # ---- 測試前載入最佳模型 ----\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for csi_inputs, labels in test_loader:\n",
    "            csi_inputs, labels = csi_inputs.to(device), labels.to(device)\n",
    "            target_class = torch.argmax(labels, dim=1)\n",
    "            class_out = model(csi_inputs)\n",
    "            pred = torch.argmax(class_out, dim=1)\n",
    "            all_pred.extend(pred.cpu().numpy())\n",
    "            all_true.extend(target_class.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(all_true) + 1\n",
    "    y_pred = np.array(all_pred) + 1\n",
    "    acc = 100 * np.mean(y_true == y_pred)\n",
    "    mde, error = compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "\n",
    "    test_accs.append(acc)\n",
    "    test_mdes.append(mde)\n",
    "    all_run_errors.append(error)\n",
    "\n",
    "    print(f\"✅ Run {run}: Acc = {acc:.2f}%, MDE = {mde:.4f}\")\n",
    "\n",
    "os.makedirs(\"repeat_2_4/00\", exist_ok=True)\n",
    "df = pd.DataFrame({\n",
    "    \"run\": list(range(1, num_runs+1)),\n",
    "    \"accuracy\": test_accs,\n",
    "    \"mde\": test_mdes\n",
    "})\n",
    "df.to_csv(\"repeat_2_4/00/csicls_results00_b2.csv\", index=False)\n",
    "# 儲存所有 error（長條格式）\n",
    "\n",
    "# 儲存結果\n",
    "errors_flat = []\n",
    "for run_idx, errors in enumerate(all_run_errors):\n",
    "    for sample_idx, e in enumerate(errors):\n",
    "        errors_flat.append({\n",
    "            \"run\": run_idx + 1,\n",
    "            \"sample_idx\": sample_idx + 1,\n",
    "            \"error\": e\n",
    "        })\n",
    "df_errors = pd.DataFrame(errors_flat)\n",
    "os.makedirs(\"repeat_2_4/00\", exist_ok=True)\n",
    "df_errors.to_csv(\"repeat_2_4/00/csicls_all_errors00_b2.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d6b95a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_DualHead(nn.Module):\n",
    "    def __init__(self, num_classes=49, regression_dim=2):\n",
    "        super(CNN_DualHead, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.flatten_dim = 128 * 12  # 48 -> 24 -> 12 after pooling\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        # Two heads: classification & regression\n",
    "        self.class_head = nn.Linear(64, num_classes)     # 分類 head\n",
    "        self.reg_head = nn.Linear(64, regression_dim)    # 回歸 head (預設 2 維)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        if x.shape[1] != 1:\n",
    "            x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        class_out = self.class_head(x)  # 分類輸出 (logits)\n",
    "        reg_out = self.reg_head(x)      # 回歸輸出 (通常 2 維)\n",
    "\n",
    "        return class_out, reg_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca102f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Alpha = 0.1]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 94.11%, MDE = 0.2424 ± 1.0790\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 95.17%, MDE = 0.2017 ± 1.0005\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 94.60%, MDE = 0.2195 ± 1.0255\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 95.01%, MDE = 0.1954 ± 0.9544\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 93.61%, MDE = 0.2535 ± 1.0842\n",
      "\n",
      "[Alpha = 0.2]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 92.10%, MDE = 0.3284 ± 1.2420\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 92.43%, MDE = 0.3048 ± 1.1884\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 93.41%, MDE = 0.2711 ± 1.1290\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 95.13%, MDE = 0.1934 ± 0.9625\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 94.97%, MDE = 0.1995 ± 0.9704\n",
      "\n",
      "[Alpha = 0.3]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 92.55%, MDE = 0.2797 ± 1.1185\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 94.76%, MDE = 0.2029 ± 0.9616\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 94.43%, MDE = 0.2215 ± 1.0224\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 94.76%, MDE = 0.1966 ± 0.9435\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 95.05%, MDE = 0.1924 ± 0.9396\n",
      "\n",
      "[Alpha = 0.4]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 92.43%, MDE = 0.2959 ± 1.1608\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 93.12%, MDE = 0.2652 ± 1.1004\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 95.01%, MDE = 0.1986 ± 0.9693\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 93.16%, MDE = 0.2541 ± 1.0525\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 93.78%, MDE = 0.2251 ± 1.0068\n",
      "\n",
      "[Alpha = 0.5]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 95.17%, MDE = 0.1822 ± 0.9154\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 92.18%, MDE = 0.2875 ± 1.1134\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 94.06%, MDE = 0.2203 ± 0.9925\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 77.57%, MDE = 0.8682 ± 1.8313\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 84.28%, MDE = 0.5915 ± 1.5492\n",
      "\n",
      "[Alpha = 0.6]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 87.15%, MDE = 0.4611 ± 1.3981\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 86.08%, MDE = 0.5040 ± 1.4111\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 94.43%, MDE = 0.2122 ± 0.9917\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 94.23%, MDE = 0.2168 ± 1.0010\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 93.29%, MDE = 0.2517 ± 1.0691\n",
      "\n",
      "[Alpha = 0.7]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 93.00%, MDE = 0.2696 ± 1.0929\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 91.49%, MDE = 0.3232 ± 1.1830\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 93.25%, MDE = 0.2418 ± 1.0283\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 93.74%, MDE = 0.2387 ± 1.0404\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 93.66%, MDE = 0.2322 ± 1.0180\n",
      "\n",
      "[Alpha = 0.8]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 93.57%, MDE = 0.2228 ± 0.9898\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 84.81%, MDE = 0.5395 ± 1.4671\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 94.19%, MDE = 0.2214 ± 1.0090\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 93.94%, MDE = 0.2048 ± 0.9354\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 85.92%, MDE = 0.4968 ± 1.4231\n",
      "\n",
      "[Alpha = 0.9]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 93.37%, MDE = 0.2379 ± 1.0196\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 66.15%, MDE = 1.2076 ± 1.9911\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 86.25%, MDE = 0.4526 ± 1.3270\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 90.59%, MDE = 0.3292 ± 1.1624\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 92.10%, MDE = 0.2898 ± 1.1337\n",
      "\n",
      "[Alpha = 1.0]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 86.04%, MDE = 0.4932 ± 1.4032\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 91.44%, MDE = 0.2764 ± 1.0696\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 79.86%, MDE = 0.6950 ± 1.6240\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 90.46%, MDE = 0.3455 ± 1.2111\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 92.35%, MDE = 0.2677 ± 1.0686\n",
      "\n",
      "=== DONE ===\n"
     ]
    }
   ],
   "source": [
    "# def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "#     \"\"\"\n",
    "#     y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "#     coordinates: dict, label -> (x, y)\n",
    "#     \"\"\"\n",
    "#     errors = []\n",
    "\n",
    "#     for true_label, pred_label in zip(y_true, y_pred):\n",
    "#         # 取出對應的座標\n",
    "#         if true_label not in coordinates or pred_label not in coordinates:\n",
    "#             # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "#             print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "#             continue\n",
    "#         true_coord = np.array(coordinates[true_label])\n",
    "#         pred_coord = np.array(coordinates[pred_label])\n",
    "#         # 計算歐氏距離\n",
    "#         error = np.linalg.norm(pred_coord - true_coord)\n",
    "#         errors.append(error)\n",
    "#     return np.mean(errors) , np.std(errors)\n",
    "\n",
    "# COORDINATES = {\n",
    "#     # 下邊界 (1-10 和 40-31)\n",
    "#     1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "#     36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "#     # 左邊界 (1-11)\n",
    "#     2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "#     6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "#     # 上邊界 (11-21)\n",
    "#     12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "#     16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "#     20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "#     # 右邊界 (21-31)\n",
    "#     22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "#     26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "#     # 中間點 (41-49)\n",
    "#     41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "#     44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "#     47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "# }\n",
    "\n",
    "# def labels_to_coords(label_tensor, coord_dict):\n",
    "#     coords = []\n",
    "#     for label in label_tensor:\n",
    "#         # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "#         coords.append(coord_dict[label.item() + 1])\n",
    "#     return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)\n",
    "\n",
    "# # ---------- 3. 訓練設定 ----------\n",
    "# device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# criterion_cls  = nn.CrossEntropyLoss()\n",
    "# criterion_reg  = nn.MSELoss()\n",
    "\n",
    "# alphas   = np.arange(0.1, 1.1, 0.1)\n",
    "# num_runs = 5\n",
    "# epochs   = 200\n",
    "# patience = 20\n",
    "\n",
    "# summary_results = []\n",
    "\n",
    "# # 假設 train_loader / val_loader / test_loader 僅回傳 (csi_inputs, labels)\n",
    "# for alpha in alphas:\n",
    "#     run_acc, run_mde, run_mde_std = [], [], []\n",
    "\n",
    "#     print(f\"\\n[Alpha = {alpha:.1f}]  Start {num_runs} runs\")\n",
    "#     for run in range(1, num_runs + 1):\n",
    "#         print(f\"Run {run}/{num_runs}\")\n",
    "#         model = CNN_DualHead(num_classes=49).to(device)\n",
    "#         optimzr = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#         sched   = optim.lr_scheduler.ReduceLROnPlateau(optimzr, 'min', 0.5, patience=15)\n",
    "#         best_val, wait = float('inf'), 0\n",
    "\n",
    "#         # ----- training with early-stop -----\n",
    "#         for epoch in range(epochs):\n",
    "#             model.train()\n",
    "#             for csi_x, labels in train_loader:\n",
    "#                 csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "#                 target = torch.argmax(labels, 1)\n",
    "\n",
    "#                 cls_out, reg_out = model(csi_x)\n",
    "#                 loss_cls = criterion_cls(cls_out, target)\n",
    "\n",
    "\n",
    "#                 loss_reg = criterion_reg(reg_out, labels_to_coords(target, COORDINATES))\n",
    "#                 loss = loss_cls + alpha * loss_reg\n",
    "\n",
    "#                 optimzr.zero_grad(); loss.backward(); optimzr.step()\n",
    "\n",
    "#             # ----- validation -----\n",
    "#             model.eval(); val_loss = 0\n",
    "#             with torch.no_grad():\n",
    "#                 for csi_x, labels in val_loader:\n",
    "#                     csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "#                     target = torch.argmax(labels, 1)\n",
    "#                     cls_out, reg_out = model(csi_x)\n",
    "#                     v_loss = criterion_cls(cls_out, target) \\\n",
    "#                            + alpha * criterion_reg(reg_out, labels_to_coords(target, COORDINATES))\n",
    "#                     val_loss += v_loss.item() * csi_x.size(0)\n",
    "\n",
    "#             val_loss /= len(val_loader.dataset)\n",
    "#             sched.step(val_loss)\n",
    "\n",
    "#             if val_loss < best_val:\n",
    "#                 best_val, wait = val_loss, 0\n",
    "#             else:\n",
    "#                 wait += 1\n",
    "#                 if wait >= patience:\n",
    "#                     break\n",
    "\n",
    "#         # ----- testing -----\n",
    "#         model.eval(); y_true, y_pred = [], []\n",
    "#         with torch.no_grad():\n",
    "#             for csi_x, labels in test_loader:\n",
    "#                 csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "#                 target = torch.argmax(labels, 1)\n",
    "#                 cls_out, _ = model(csi_x)\n",
    "#                 pred = torch.argmax(cls_out, 1)\n",
    "#                 y_true.extend((target.cpu().numpy() + 1))   # 轉 1-index\n",
    "#                 y_pred.extend((pred.cpu().numpy()   + 1))\n",
    "\n",
    "#         acc            = 100 * np.mean(np.array(y_true) == np.array(y_pred))\n",
    "#         mde_mean, mde_sd = compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "\n",
    "#         run_acc.append(acc); run_mde.append(mde_mean); run_mde_std.append(mde_sd)\n",
    "#         print(f\"✅ Run {run}: Acc = {acc:.2f}%, MDE = {mde_mean:.4f} ± {mde_sd:.4f}\")\n",
    "\n",
    "#     # ----- 儲存每個 α 的結果 -----\n",
    "#     alpha_id = int(round(alpha * 10))\n",
    "#     folder   = f\"repeat_2_4/{alpha_id:02d}\"\n",
    "#     os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "#     pd.DataFrame({\n",
    "#         'run':     range(1, num_runs + 1),\n",
    "#         'accuracy':run_acc,\n",
    "#         'mde':     run_mde,\n",
    "#         'mde_std': run_mde_std\n",
    "#     }).to_csv(f\"{folder}/csi_cls_reg_results{alpha_id:02d}.csv\", index=False)\n",
    "\n",
    "#     summary_results.append({\n",
    "#         'alpha':   alpha,\n",
    "#         'avg_acc': np.mean(run_acc),\n",
    "#         'std_acc': np.std(run_acc),\n",
    "#         'avg_mde': np.mean(run_mde),\n",
    "#         'std_mde': np.std(run_mde)\n",
    "#     })\n",
    "\n",
    "# # 最後整合各 α 統計\n",
    "# summary_df = pd.DataFrame(summary_results)\n",
    "# # summary_df.to_csv(\"csi_alpha_comparison_summary.csv\", index=False)\n",
    "# print(\"\\n=== DONE ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda53d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Alpha = 0.1]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 96.07%, MDE = 0.1639 ± 0.8937\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 95.54%, MDE = 0.1871 ± 0.9546\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 95.74%, MDE = 0.1785 ± 0.9352\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 96.32%, MDE = 0.1568 ± 0.8814\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 96.36%, MDE = 0.1550 ± 0.8784\n",
      "\n",
      "[Alpha = 0.2]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 96.11%, MDE = 0.1667 ± 0.9067\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 96.11%, MDE = 0.1644 ± 0.8923\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 96.44%, MDE = 0.1525 ± 0.8656\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 96.40%, MDE = 0.1562 ± 0.8731\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 96.40%, MDE = 0.1597 ± 0.8924\n",
      "\n",
      "[Alpha = 0.3]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 96.40%, MDE = 0.1508 ± 0.8545\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 96.36%, MDE = 0.1569 ± 0.8780\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 96.15%, MDE = 0.1593 ± 0.8840\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 96.23%, MDE = 0.1593 ± 0.8705\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 95.87%, MDE = 0.1752 ± 0.9210\n",
      "\n",
      "[Alpha = 0.4]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 96.36%, MDE = 0.1575 ± 0.8749\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 95.99%, MDE = 0.1602 ± 0.8693\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 96.11%, MDE = 0.1528 ± 0.8564\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 95.95%, MDE = 0.1732 ± 0.9213\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 96.19%, MDE = 0.1554 ± 0.8638\n",
      "\n",
      "[Alpha = 0.5]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 95.91%, MDE = 0.1672 ± 0.8880\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 96.28%, MDE = 0.1530 ± 0.8657\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 95.99%, MDE = 0.1631 ± 0.8861\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 95.42%, MDE = 0.1849 ± 0.9376\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 96.28%, MDE = 0.1422 ± 0.8103\n",
      "\n",
      "[Alpha = 0.6]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 95.95%, MDE = 0.1635 ± 0.8767\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 95.58%, MDE = 0.1762 ± 0.9172\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 96.48%, MDE = 0.1372 ± 0.8104\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 96.03%, MDE = 0.1532 ± 0.8448\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 95.74%, MDE = 0.1670 ± 0.8762\n",
      "\n",
      "[Alpha = 0.7]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 96.15%, MDE = 0.1533 ± 0.8481\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 96.03%, MDE = 0.1547 ± 0.8461\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 95.99%, MDE = 0.1669 ± 0.8950\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 96.15%, MDE = 0.1584 ± 0.8729\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 96.03%, MDE = 0.1519 ± 0.8220\n",
      "\n",
      "[Alpha = 0.8]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 95.21%, MDE = 0.1889 ± 0.9559\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 96.07%, MDE = 0.1649 ± 0.8913\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 95.91%, MDE = 0.1661 ± 0.8888\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 95.87%, MDE = 0.1605 ± 0.8704\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 95.91%, MDE = 0.1574 ± 0.8570\n",
      "\n",
      "[Alpha = 0.9]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 95.87%, MDE = 0.1610 ± 0.8709\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 95.66%, MDE = 0.1799 ± 0.9357\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 95.78%, MDE = 0.1714 ± 0.9023\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 95.29%, MDE = 0.1761 ± 0.9034\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 95.66%, MDE = 0.1604 ± 0.8487\n",
      "\n",
      "[Alpha = 1.0]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 95.91%, MDE = 0.1651 ± 0.8865\n",
      "Run 2/5\n",
      "✅ Run 2: Acc = 95.82%, MDE = 0.1728 ± 0.9185\n",
      "Run 3/5\n",
      "✅ Run 3: Acc = 95.42%, MDE = 0.1704 ± 0.8727\n",
      "Run 4/5\n",
      "✅ Run 4: Acc = 96.32%, MDE = 0.1493 ± 0.8485\n",
      "Run 5/5\n",
      "✅ Run 5: Acc = 95.62%, MDE = 0.1638 ± 0.8615\n",
      "\n",
      "=== DONE ===\n"
     ]
    }
   ],
   "source": [
    "# def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "#     \"\"\"\n",
    "#     y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "#     coordinates: dict, label -> (x, y)\n",
    "#     \"\"\"\n",
    "#     errors = []\n",
    "\n",
    "#     for true_label, pred_label in zip(y_true, y_pred):\n",
    "#         # 取出對應的座標\n",
    "#         if true_label not in coordinates or pred_label not in coordinates:\n",
    "#             # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "#             print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "#             continue\n",
    "#         true_coord = np.array(coordinates[true_label])\n",
    "#         pred_coord = np.array(coordinates[pred_label])\n",
    "#         # 計算歐氏距離\n",
    "#         error = np.linalg.norm(pred_coord - true_coord)\n",
    "#         errors.append(error)\n",
    "#     return np.mean(errors) , np.std(errors)\n",
    "\n",
    "\n",
    "\n",
    "# # 這個給上面 \"all_run_errors\" 用，直接回傳所有error vector\n",
    "# def compute_mean_distance_error_full(y_true, y_pred, coordinates):\n",
    "#     errors = []\n",
    "#     for true_label, pred_label in zip(y_true, y_pred):\n",
    "#         if true_label not in coordinates or pred_label not in coordinates:\n",
    "#             print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "#             continue\n",
    "#         true_coord = np.array(coordinates[true_label])\n",
    "#         pred_coord = np.array(coordinates[pred_label])\n",
    "#         error = np.linalg.norm(pred_coord - true_coord)\n",
    "#         errors.append(error)\n",
    "#     return np.mean(errors), errors\n",
    "\n",
    "# COORDINATES = {\n",
    "#     # 下邊界 (1-10 和 40-31)\n",
    "#     1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "#     36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "#     # 左邊界 (1-11)\n",
    "#     2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "#     6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "#     # 上邊界 (11-21)\n",
    "#     12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "#     16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "#     20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "#     # 右邊界 (21-31)\n",
    "#     22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "#     26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "#     # 中間點 (41-49)\n",
    "#     41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "#     44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "#     47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# def labels_to_coords(label_tensor, coord_dict):\n",
    "#     coords = []\n",
    "#     for label in label_tensor:\n",
    "#         # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "#         coords.append(coord_dict[label.item() + 1])\n",
    "#     return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)\n",
    "\n",
    "\n",
    "# # ---------- 3. 訓練設定 ----------\n",
    "# device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# criterion_cls  = nn.CrossEntropyLoss()\n",
    "# criterion_reg  = nn.MSELoss()\n",
    "\n",
    "# alphas   = np.arange(0.1, 1.1, 0.1)\n",
    "# num_runs = 5\n",
    "# epochs   = 200\n",
    "# patience = 20\n",
    "\n",
    "# summary_results = []\n",
    "\n",
    "\n",
    "\n",
    "# for alpha in alphas:\n",
    "#     run_acc, run_mde, run_mde_std = [], [], []\n",
    "#     all_run_errors = []  # 每個 run 的 errors 都存進來\n",
    "\n",
    "#     print(f\"\\n[Alpha = {alpha:.1f}]  Start {num_runs} runs\")\n",
    "#     for run in range(1, num_runs + 1):\n",
    "#         print(f\"Run {run}/{num_runs}\")\n",
    "#         model = CNN_DualHead(num_classes=49).to(device)\n",
    "#         optimzr = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#         sched   = optim.lr_scheduler.ReduceLROnPlateau(optimzr, 'min', 0.5, patience=15)\n",
    "#         best_val, wait = float('inf'), 0\n",
    "#         best_model_path = \"best_model_tmp.pth\"\n",
    "\n",
    "#         # ----- training with early-stop -----\n",
    "#         for epoch in range(epochs):\n",
    "#             model.train()\n",
    "#             for csi_x, labels in train_loader:\n",
    "#                 csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "#                 target = torch.argmax(labels, 1)\n",
    "\n",
    "#                 cls_out, reg_out = model(csi_x)\n",
    "#                 loss_cls = criterion_cls(cls_out, target)\n",
    "#                 loss_reg = criterion_reg(reg_out, labels_to_coords(target, COORDINATES))\n",
    "#                 loss = loss_cls + alpha * loss_reg\n",
    "\n",
    "#                 optimzr.zero_grad(); loss.backward(); optimzr.step()\n",
    "\n",
    "#             # ----- validation -----\n",
    "#             model.eval(); val_loss = 0\n",
    "#             with torch.no_grad():\n",
    "#                 for csi_x, labels in val_loader:\n",
    "#                     csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "#                     target = torch.argmax(labels, 1)\n",
    "#                     cls_out, reg_out = model(csi_x)\n",
    "#                     v_loss = criterion_cls(cls_out, target) \\\n",
    "#                            + alpha * criterion_reg(reg_out, labels_to_coords(target, COORDINATES))\n",
    "#                     val_loss += v_loss.item() * csi_x.size(0)\n",
    "\n",
    "#             val_loss /= len(val_loader.dataset)\n",
    "#             sched.step(val_loss)\n",
    "\n",
    "#             if val_loss < best_val:\n",
    "#                 best_val, wait = val_loss, 0\n",
    "#                 # --- save best model ---\n",
    "#                 torch.save(model.state_dict(), best_model_path)\n",
    "#             else:\n",
    "#                 wait += 1\n",
    "#                 if wait >= patience:\n",
    "#                     break\n",
    "\n",
    "#         # ----- 測試用最佳模型 -----\n",
    "#         model.load_state_dict(torch.load(best_model_path))\n",
    "#         model.eval()\n",
    "#         y_true, y_pred, errors = [], [], []\n",
    "#         with torch.no_grad():\n",
    "#             for csi_x, labels in test_loader:\n",
    "#                 csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "#                 target = torch.argmax(labels, 1)\n",
    "#                 cls_out, _ = model(csi_x)\n",
    "#                 pred = torch.argmax(cls_out, 1)\n",
    "#                 y_true.extend((target.cpu().numpy() + 1))   # 轉 1-index\n",
    "#                 y_pred.extend((pred.cpu().numpy()   + 1))\n",
    "\n",
    "#         # 計算每一筆誤差\n",
    "#         mde_mean, mde_sd = compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "#         # 額外記錄所有 errors (逐筆)\n",
    "#         _, err_vec = compute_mean_distance_error_full(y_true, y_pred, COORDINATES)  # <--- 見下說明\n",
    "\n",
    "#         run_acc.append(100 * np.mean(np.array(y_true) == np.array(y_pred)))\n",
    "#         run_mde.append(mde_mean)\n",
    "#         run_mde_std.append(mde_sd)\n",
    "#         all_run_errors.append(err_vec)\n",
    "\n",
    "#         print(f\"✅ Run {run}: Acc = {run_acc[-1]:.2f}%, MDE = {mde_mean:.4f} ± {mde_sd:.4f}\")\n",
    "\n",
    "#     # ===== 每個 alpha 儲存完整誤差 =====\n",
    "#     alpha_id = int(round(alpha * 10))\n",
    "#     folder   = f\"repeat_2_4/{alpha_id:02d}\"\n",
    "#     os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "#     # 統計檔\n",
    "#     pd.DataFrame({\n",
    "#         'run':     range(1, num_runs + 1),\n",
    "#         'accuracy':run_acc,\n",
    "#         'mde':     run_mde,\n",
    "#         'mde_std': run_mde_std\n",
    "#     }).to_csv(f\"{folder}/csi_cls_reg_results{alpha_id:02d}_b2.csv\", index=False)\n",
    "\n",
    "#     # 儲存所有誤差（長條格式）\n",
    "#     errors_flat = []\n",
    "#     for run_idx, errors in enumerate(all_run_errors):\n",
    "#         for sample_idx, e in enumerate(errors):\n",
    "#             errors_flat.append({\n",
    "#                 \"run\": run_idx + 1,\n",
    "#                 \"sample_idx\": sample_idx + 1,\n",
    "#                 \"error\": e\n",
    "#             })\n",
    "#     pd.DataFrame(errors_flat).to_csv(f\"{folder}/csi_cls_reg_all_errors{alpha_id:02d}_b2.csv\", index=False)\n",
    "\n",
    "#     summary_results.append({\n",
    "#         'alpha':   alpha,\n",
    "#         'avg_acc': np.mean(run_acc),\n",
    "#         'std_acc': np.std(run_acc),\n",
    "#         'avg_mde': np.mean(run_mde),\n",
    "#         'std_mde': np.std(run_mde)\n",
    "#     })\n",
    "\n",
    "# # ... summary_results 統計照舊\n",
    "\n",
    "# print(\"\\n=== DONE ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#測試CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90a22de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Alpha = 0.1]  Start 5 runs\n",
      "Run 1/5\n",
      "✅ Run 1: Acc = 96.64%, MDE = 0.1530 ± 0.8843\n",
      "Run 2/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(labels, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    100\u001b[0m cls_out, reg_out \u001b[38;5;241m=\u001b[39m model(csi_x)\n\u001b[0;32m--> 101\u001b[0m loss_cls \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m loss_reg \u001b[38;5;241m=\u001b[39m criterion_reg(reg_out, labels_to_coords(target, COORDINATES))\n\u001b[1;32m    103\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_cls \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m loss_reg\n",
      "File \u001b[0;32m~/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/nn/modules/loss.py:1295\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kyle_ai/lib/python3.12/site-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_mean_distance_error(y_true, y_pred, coordinates):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: 一維的 NumPy 陣列，分別存放真實和預測的 label（整數）\n",
    "    coordinates: dict, label -> (x, y)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        # 取出對應的座標\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            # 若某個 label 不在座標字典內，就跳過（或視需求處理）\n",
    "            print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        # 計算歐氏距離\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors) , np.std(errors)\n",
    "\n",
    "\n",
    "\n",
    "# 這個給上面 \"all_run_errors\" 用，直接回傳所有error vector\n",
    "def compute_mean_distance_error_full(y_true, y_pred, coordinates):\n",
    "    errors = []\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        if true_label not in coordinates or pred_label not in coordinates:\n",
    "            print(f\"Label {true_label} or {pred_label} not in coordinates.\")\n",
    "            continue\n",
    "        true_coord = np.array(coordinates[true_label])\n",
    "        pred_coord = np.array(coordinates[pred_label])\n",
    "        error = np.linalg.norm(pred_coord - true_coord)\n",
    "        errors.append(error)\n",
    "    return np.mean(errors), errors\n",
    "\n",
    "COORDINATES = {\n",
    "    # 下邊界 (1-10 和 40-31)\n",
    "    1: (0, 0), 40: (0.6, 0), 39: (1.2, 0), 38: (1.8, 0), 37: (2.4, 0),\n",
    "    36: (3.0, 0), 35: (3.6, 0), 34: (4.2, 0), 33: (4.8, 0), 32: (5.4, 0), 31: (6.0, 0),\n",
    "    # 左邊界 (1-11)\n",
    "    2: (0, 0.6), 3: (0, 1.2), 4: (0, 1.8), 5: (0, 2.4),\n",
    "    6: (0, 3.0), 7: (0, 3.6), 8: (0, 4.2), 9: (0, 4.8), 10: (0, 5.4), 11: (0, 6.0),\n",
    "    # 上邊界 (11-21)\n",
    "    12: (0.6, 6.0), 13: (1.2, 6.0), 14: (1.8, 6.0), 15: (2.4, 6.0),\n",
    "    16: (3.0, 6.0), 17: (3.6, 6.0), 18: (4.2, 6.0), 19: (4.8, 6.0),\n",
    "    20: (5.4, 6.0), 21: (6.0, 6.0),\n",
    "    # 右邊界 (21-31)\n",
    "    22: (6.0, 5.4), 23: (6.0, 4.8), 24: (6.0, 4.2), 25: (6.0, 3.6),\n",
    "    26: (6.0, 3.0), 27: (6.0, 2.4), 28: (6.0, 1.8), 29: (6.0, 1.2), 30: (6.0, 0.6),\n",
    "    # 中間點 (41-49)\n",
    "    41: (3.0, 0.6), 42: (3.0, 1.2), 43: (3.0, 1.8),\n",
    "    44: (3.0, 2.4), 45: (3.0, 3.0), 46: (3.0, 3.6),\n",
    "    47: (3.0, 4.2), 48: (3.0, 4.8), 49: (3.0, 5.4)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def labels_to_coords(label_tensor, coord_dict):\n",
    "    coords = []\n",
    "    for label in label_tensor:\n",
    "        # 將 0-index 轉換成 1-index (例如 0 -> 1, 1 -> 2, ..., 48 -> 49)\n",
    "        coords.append(coord_dict[label.item() + 1])\n",
    "    return torch.tensor(coords, dtype=torch.float32, device=label_tensor.device)\n",
    "\n",
    "\n",
    "# ---------- 3. 訓練設定 ----------\n",
    "device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion_cls  = nn.CrossEntropyLoss()\n",
    "criterion_reg  = nn.MSELoss()\n",
    "\n",
    "alphas   = np.arange(0.1, 1.1, 0.1)\n",
    "num_runs = 5\n",
    "epochs   = 200\n",
    "patience = 20\n",
    "\n",
    "summary_results = []\n",
    "\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "    run_acc, run_mde, run_mde_std = [], [], []\n",
    "    all_run_errors = []  # 每個 run 的 errors 都存進來\n",
    "\n",
    "    print(f\"\\n[Alpha = {alpha:.1f}]  Start {num_runs} runs\")\n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"Run {run}/{num_runs}\")\n",
    "        model = CNN_DualHead(num_classes=49).to(device)\n",
    "        optimzr = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        sched   = optim.lr_scheduler.ReduceLROnPlateau(optimzr, 'min', 0.5, patience=15)\n",
    "        best_val, wait = float('inf'), 0\n",
    "        best_model_path = \"best_model_tmp.pth\"\n",
    "\n",
    "        # ----- training with early-stop -----\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for csi_x, labels in train_loader:\n",
    "                csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "                target = torch.argmax(labels, 1)\n",
    "\n",
    "                cls_out, reg_out = model(csi_x)\n",
    "                loss_cls = criterion_cls(cls_out, target)\n",
    "                loss_reg = criterion_reg(reg_out, labels_to_coords(target, COORDINATES))\n",
    "                loss = loss_cls + alpha * loss_reg\n",
    "\n",
    "                optimzr.zero_grad(); loss.backward(); optimzr.step()\n",
    "\n",
    "            # ----- validation -----\n",
    "            model.eval(); val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for csi_x, labels in val_loader:\n",
    "                    csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "                    target = torch.argmax(labels, 1)\n",
    "                    cls_out, reg_out = model(csi_x)\n",
    "                    v_loss = criterion_cls(cls_out, target) \\\n",
    "                           + alpha * criterion_reg(reg_out, labels_to_coords(target, COORDINATES))\n",
    "                    val_loss += v_loss.item() * csi_x.size(0)\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            sched.step(val_loss)\n",
    "\n",
    "            if val_loss < best_val:\n",
    "                best_val, wait = val_loss, 0\n",
    "                # --- save best model ---\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    break\n",
    "\n",
    "        # ----- 測試用最佳模型 -----\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "        model.eval()\n",
    "        y_true, y_pred, errors = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for csi_x, labels in test_loader:\n",
    "                csi_x, labels = csi_x.to(device), labels.to(device)\n",
    "                target = torch.argmax(labels, 1)\n",
    "                cls_out, _ = model(csi_x)\n",
    "                pred = torch.argmax(cls_out, 1)\n",
    "                y_true.extend((target.cpu().numpy() + 1))   # 轉 1-index\n",
    "                y_pred.extend((pred.cpu().numpy()   + 1))\n",
    "\n",
    "        # 計算每一筆誤差\n",
    "        mde_mean, mde_sd = compute_mean_distance_error(y_true, y_pred, COORDINATES)\n",
    "        # 額外記錄所有 errors (逐筆)\n",
    "        _, err_vec = compute_mean_distance_error_full(y_true, y_pred, COORDINATES)  # <--- 見下說明\n",
    "\n",
    "        run_acc.append(100 * np.mean(np.array(y_true) == np.array(y_pred)))\n",
    "        run_mde.append(mde_mean)\n",
    "        run_mde_std.append(mde_sd)\n",
    "        all_run_errors.append(err_vec)\n",
    "\n",
    "        print(f\"✅ Run {run}: Acc = {run_acc[-1]:.2f}%, MDE = {mde_mean:.4f} ± {mde_sd:.4f}\")\n",
    "\n",
    "    # ===== 每個 alpha 儲存完整誤差 =====\n",
    "    # alpha_id = int(round(alpha * 10))\n",
    "    # folder   = f\"repeat_2_4/{alpha_id:02d}\"\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # 統計檔\n",
    "    # pd.DataFrame({\n",
    "    #     'run':     range(1, num_runs + 1),\n",
    "    #     'accuracy':run_acc,\n",
    "    #     'mde':     run_mde,\n",
    "    #     'mde_std': run_mde_std\n",
    "    # }).to_csv(f\"{folder}/csi_cls_reg_results{alpha_id:02d}_b2.csv\", index=False)\n",
    "\n",
    "    # 儲存所有誤差（長條格式）\n",
    "    # errors_flat = []\n",
    "    # for run_idx, errors in enumerate(all_run_errors):\n",
    "    #     for sample_idx, e in enumerate(errors):\n",
    "    #         errors_flat.append({\n",
    "    #             \"run\": run_idx + 1,\n",
    "    #             \"sample_idx\": sample_idx + 1,\n",
    "    #             \"error\": e\n",
    "    #         })\n",
    "    #pd.DataFrame(errors_flat).to_csv(f\"{folder}/csi_cls_reg_all_errors{alpha_id:02d}_b2.csv\", index=False)\n",
    "\n",
    "    # summary_results.append({\n",
    "    #     'alpha':   alpha,\n",
    "    #     'avg_acc': np.mean(run_acc),\n",
    "    #     'std_acc': np.std(run_acc),\n",
    "    #     'avg_mde': np.mean(run_mde),\n",
    "    #     'std_mde': np.std(run_mde)\n",
    "    # })\n",
    "\n",
    "# ... summary_results 統計照舊\n",
    "\n",
    "print(\"\\n=== DONE ===\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
